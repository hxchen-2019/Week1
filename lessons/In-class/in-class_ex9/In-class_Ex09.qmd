---
title: "In Class Exercise 9"
author: "Hao Xian"
date: "13 March 2023"
date-modified: "13 March 2023"
format: html
number-sections: true
execute: 
  echo: true
  eval: true
  message: false
  warning: false
  
editor: visual
---

::: callout-note
Use the MPSZ-2019 Dataset for Take Home Exercise 3
:::

# Loading the packages

```{r}
pacman::p_load(sf, spdep, GWmodel, SpatialML, tidyverse, tmap, ggpubr, olsrr, devtools, tidymodels)

#if tidymodels does not load, you can just rsample
```

# Preparing Data

## Reading data file from RDS

Reading the input data sets. It is in a simple data frame

```{r}
mdata <- read_rds("data/aspatial/mdata.rds")
```

## Data Sampling

The entire data are split into training and test data sets

```{r}
set.seed(1234)
resale_split <- initial_split(mdata,
                              prop = 6.5/10)
train_data <- training(resale_split)
test_data <- testing(resale_split)
```

```{r}
#| eval: false  
write_rds(train_data, "data/model/train_data.rds")
write_rds(test_data, "data/model/test_data.rds")
```

# Computing Correlation Matrix

```{r}
mdata_nogeo <- mdata %>%
  st_drop_geometry()
corrplot::corrplot(cor(mdata_nogeo[, 2:17]))


  
```

```{r}
train_data <- read_rds("data/model/train_data.rds")
test_data <- read_rds("data/model/test_data.rds")
```

::: callout-note
We are not too particular on the R Square, we focus more on the Residual Standard Error.
:::

```{r}
price_mlr <- lm(resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN + WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,
data = train_data)
  summary(price_mlr)
```

```{r}
#| eval: false  
write_rds(price_mlr, "data/model/price_mlr.rds")
```

# Converting the sf data frame to Spatial Point Data Frame

```{r}
train_data_sp <- as_Spatial(train_data)
train_data_sp
```

## Computing Adaptive Bandwidth

```{r}

```

# Preparing Coordinate Data

## Extracting coordinates data

::: callout-note
This extracts out the coordinates and store it
:::

```{r}
coords <- st_coordinates(mdata)
coords_train <- st_coordinates(train_data)
coords_test <- st_coordinates(test_data)
```

```{r}
coords_train <- write_rds(coords_train, "data/model/coords_train.rds")
coords_test <- write_rds(coords_test, "data/model/coords_test.rds")
```

## Dropping Geometry Field

```{r}
train_data <- train_data %>%
  st_drop_geometry()
```

# Calibrating Random Forest

```{r}
#| eval: false
set.seed(1234)
rf <- ranger(resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN + WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,
data = train_data)

```

::: callout-note
This only works without the geometry file.
:::

```{r}
#| eval: false
print(rf)
```

::: callout-note
For performance, Look at MSE as the main source Error. We will need to square-root the MSE.
:::

# Calibrating Geographically weighted Random Forest

::: callout-note
We need to look at the grd documentation.
:::

```{r}
#| eval: false
set.seed(1234)
gwRD_adaptive <- grf(formula = resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN + WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,
dframe = train_data,
bw=55,
kernel = "adaptive",
coords = coords_train)
```

::: callout-note
How do we determine the Bandwidth, we can borrow the bandwidth. The better methods is to calculate with grf.bw().
:::

There are 2 parts to the result, the first section is for explanatory model. the second section is for predictor model. We are looking at AIC model to compare.

## Saving the Model

```{r}
#| eval: false
write_rds(gwRD_adaptive, "data/model/gwRF_adaptive.rds")
```

## Read the model

```{r}
#| eval: false
gwRF_adaptive <- read_rds("data/model/gwRF_adaptive.rds")
```

We can view the information and load it into a data frame so that we can report it.

```{r}
#| eval: false
vi_df <- as.data.frame(gwRF_adaptive$Global.Model$variable.importance)
vi_df
```

## Predicting the using the test data

We will combine the test data with its corresponding coordinates data

```{r}
#| eval: false
test_data <- cbind(test_data, coords_test) %>%
  st_drop_geometry()
```

### Predicting with test data

```{r}
#| eval: false
gwRF_ored <- predict.grf(gwRF_adaptive, 
                         test_data,
                         x.var.name="X",
                         y.var.name="Y",
                         local.w=1,
                         global.w=0)
```

```{r}
#| eval: false
write_rds(gwRF_ored, "data/model/gwRF_pred.rds")

```

### Converting to the predicting output into a data frame.

```{r}
#| eval: false
gwRF_pred <- read_rds("data/model/gwRF_pred.rds")
```

```{r}
#| eval: false
gwRF_pred_df <- as.data.frame(gwRF_pred)
```

```{r}

```

::: callout-note
We would need to plot it out to see the outliers..
:::
