[
  {
    "objectID": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html",
    "href": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html",
    "title": "Hands on Excerise 4",
    "section": "",
    "text": "pacman::p_load(maptools, sf, raster, spatstat, tmap)"
  },
  {
    "objectID": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#importing-spatial-data",
    "href": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#importing-spatial-data",
    "title": "Hands on Excerise 4",
    "section": "2.1 Importing Spatial Data",
    "text": "2.1 Importing Spatial Data\n\nchildcare_sf <- st_read(\"data/geospatial/child-care-services-geojson.geojson\") %>%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\hxchen-2019\\birdie\\lessons\\Hands-on\\Hands-on-Ex4\\data\\geospatial\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nsg_sf <- st_read(dsn = \"data/geospatial\", layer=\"CostalOutline\") %>%\n  st_transform(crs = 3414)\n\nReading layer `CostalOutline' from data source \n  `C:\\hxchen-2019\\birdie\\lessons\\Hands-on\\Hands-on-Ex4\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\nmpsz_sf <- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\") %>%\n  st_transform(crs = 3414)\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\hxchen-2019\\birdie\\lessons\\Hands-on\\Hands-on-Ex4\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21"
  },
  {
    "objectID": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#converting-to-spatial-class",
    "href": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#converting-to-spatial-class",
    "title": "Hands on Excerise 4",
    "section": "4.1 Converting to Spatial Class",
    "text": "4.1 Converting to Spatial Class\n\nchildcare <- as_Spatial(childcare_sf)\nmpsz <- as_Spatial(mpsz_sf)\nsg <- as_Spatial(sg_sf)\n\n\nchildcare\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description \nmin values  :   kml_1, <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>018989</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>1, MARINA BOULEVARD, #B1 - 01, ONE MARINA BOULEVARD, SINGAPORE 018989</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>THE LITTLE SKOOL-HOUSE INTERNATIONAL PTE. LTD.</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>08F73931F4A691F4</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center> \nmax values  : kml_999,                  <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>829646</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>200, PONGGOL SEVENTEENTH AVENUE, SINGAPORE 829646</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td>Child Care Services</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>RAFFLES KIDZ @ PUNGGOL PTE LTD</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>379D017BF244B0FA</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center> \n\n\n\nmpsz\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792 \n\n\n\nsg\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 4\nnames       : GDO_GID, MSLINK, MAPID,              COSTAL_NAM \nmin values  :       1,      1,     0,             ISLAND LINK \nmax values  :      60,     67,     0, SINGAPORE - MAIN ISLAND"
  },
  {
    "objectID": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#converting-to-generic-sp-format",
    "href": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#converting-to-generic-sp-format",
    "title": "Hands on Excerise 4",
    "section": "4.2 Converting to Generic SP Format",
    "text": "4.2 Converting to Generic SP Format\n\nchildcare_sp <- as(childcare, \"SpatialPoints\")\nsg_sp <- as(sg, \"SpatialPolygons\")\n\n\nchildcare_sp\n\nclass       : SpatialPoints \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\nsg_sp\n\nclass       : SpatialPolygons \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs"
  },
  {
    "objectID": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#converting-into-spatstatss-ppp-format",
    "href": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#converting-into-spatstatss-ppp-format",
    "title": "Hands on Excerise 4",
    "section": "4.3 Converting into spatstats’s ppp format",
    "text": "4.3 Converting into spatstats’s ppp format\n\nchildcare_ppp <- as(childcare_sp, \"ppp\")\nchildcare_ppp\n\nPlanar point pattern: 1545 points\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\n\nplot(childcare_ppp)\n\n\n\n\n\nsummary(childcare_ppp)\n\nPlanar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units"
  },
  {
    "objectID": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#viewing-the-duplicate",
    "href": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#viewing-the-duplicate",
    "title": "Hands on Excerise 4",
    "section": "5.1 Viewing the Duplicate",
    "text": "5.1 Viewing the Duplicate\n\ntmap_mode('view')\ntm_shape(childcare) +\n  tm_dots(alpha=0.4, \n          size=0.05)\n\n\n\n\n\n\n\ntmap_mode('plot')"
  },
  {
    "objectID": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#remove-duplicate-with-jittering-method",
    "href": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#remove-duplicate-with-jittering-method",
    "title": "Hands on Excerise 4",
    "section": "5.2 Remove Duplicate with jittering method",
    "text": "5.2 Remove Duplicate with jittering method\n\nchildcare_ppp_jit <- rjitter(childcare_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE"
  },
  {
    "objectID": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#creating-owin-object",
    "href": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#creating-owin-object",
    "title": "Hands on Excerise 4",
    "section": "5.3 Creating Owin Object",
    "text": "5.3 Creating Owin Object\n\nsg_owin <- as(sg_sp, \"owin\")\n\n\nplot(sg_owin)\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n60 separate polygons (no holes)\n            vertices        area relative.area\npolygon 1         38 1.56140e+04      2.09e-05\npolygon 2        735 4.69093e+06      6.27e-03\npolygon 3         49 1.66986e+04      2.23e-05\npolygon 4         76 3.12332e+05      4.17e-04\npolygon 5       5141 6.36179e+08      8.50e-01\npolygon 6         42 5.58317e+04      7.46e-05\npolygon 7         67 1.31354e+06      1.75e-03\npolygon 8         15 4.46420e+03      5.96e-06\npolygon 9         14 5.46674e+03      7.30e-06\npolygon 10        37 5.26194e+03      7.03e-06\npolygon 11        53 3.44003e+04      4.59e-05\npolygon 12        74 5.82234e+04      7.78e-05\npolygon 13        69 5.63134e+04      7.52e-05\npolygon 14       143 1.45139e+05      1.94e-04\npolygon 15       165 3.38736e+05      4.52e-04\npolygon 16       130 9.40465e+04      1.26e-04\npolygon 17        19 1.80977e+03      2.42e-06\npolygon 18        16 2.01046e+03      2.69e-06\npolygon 19        93 4.30642e+05      5.75e-04\npolygon 20        90 4.15092e+05      5.54e-04\npolygon 21       721 1.92795e+06      2.57e-03\npolygon 22       330 1.11896e+06      1.49e-03\npolygon 23       115 9.28394e+05      1.24e-03\npolygon 24        37 1.01705e+04      1.36e-05\npolygon 25        25 1.66227e+04      2.22e-05\npolygon 26        10 2.14507e+03      2.86e-06\npolygon 27       190 2.02489e+05      2.70e-04\npolygon 28       175 9.25904e+05      1.24e-03\npolygon 29      1993 9.99217e+06      1.33e-02\npolygon 30        38 2.42492e+04      3.24e-05\npolygon 31        24 6.35239e+03      8.48e-06\npolygon 32        53 6.35791e+05      8.49e-04\npolygon 33        41 1.60161e+04      2.14e-05\npolygon 34        22 2.54368e+03      3.40e-06\npolygon 35        30 1.08382e+04      1.45e-05\npolygon 36       327 2.16921e+06      2.90e-03\npolygon 37       111 6.62927e+05      8.85e-04\npolygon 38        90 1.15991e+05      1.55e-04\npolygon 39        98 6.26829e+04      8.37e-05\npolygon 40       415 3.25384e+06      4.35e-03\npolygon 41       222 1.51142e+06      2.02e-03\npolygon 42       107 6.33039e+05      8.45e-04\npolygon 43         7 2.48299e+03      3.32e-06\npolygon 44        17 3.28303e+04      4.38e-05\npolygon 45        26 8.34758e+03      1.11e-05\npolygon 46       177 4.67446e+05      6.24e-04\npolygon 47        16 3.19460e+03      4.27e-06\npolygon 48        15 4.87296e+03      6.51e-06\npolygon 49        66 1.61841e+04      2.16e-05\npolygon 50       149 5.63430e+06      7.53e-03\npolygon 51       609 2.62570e+07      3.51e-02\npolygon 52         8 7.82256e+03      1.04e-05\npolygon 53       976 2.33447e+07      3.12e-02\npolygon 54        55 8.25379e+04      1.10e-04\npolygon 55       976 2.33447e+07      3.12e-02\npolygon 56        61 3.33449e+05      4.45e-04\npolygon 57         6 1.68410e+04      2.25e-05\npolygon 58         4 9.45963e+03      1.26e-05\npolygon 59        46 6.99702e+05      9.35e-04\npolygon 60        13 7.00873e+04      9.36e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 748741000 square units\nFraction of frame area: 0.414"
  },
  {
    "objectID": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#combining-point-events-and-own-obbject",
    "href": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#combining-point-events-and-own-obbject",
    "title": "Hands on Excerise 4",
    "section": "5.4 Combining Point events and own obbject",
    "text": "5.4 Combining Point events and own obbject\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\n\nsummary(childcareSG_ppp)\n\nPlanar point pattern:  1545 points\nAverage intensity 2.063463e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: polygonal boundary\n60 separate polygons (no holes)\n            vertices        area relative.area\npolygon 1         38 1.56140e+04      2.09e-05\npolygon 2        735 4.69093e+06      6.27e-03\npolygon 3         49 1.66986e+04      2.23e-05\npolygon 4         76 3.12332e+05      4.17e-04\npolygon 5       5141 6.36179e+08      8.50e-01\npolygon 6         42 5.58317e+04      7.46e-05\npolygon 7         67 1.31354e+06      1.75e-03\npolygon 8         15 4.46420e+03      5.96e-06\npolygon 9         14 5.46674e+03      7.30e-06\npolygon 10        37 5.26194e+03      7.03e-06\npolygon 11        53 3.44003e+04      4.59e-05\npolygon 12        74 5.82234e+04      7.78e-05\npolygon 13        69 5.63134e+04      7.52e-05\npolygon 14       143 1.45139e+05      1.94e-04\npolygon 15       165 3.38736e+05      4.52e-04\npolygon 16       130 9.40465e+04      1.26e-04\npolygon 17        19 1.80977e+03      2.42e-06\npolygon 18        16 2.01046e+03      2.69e-06\npolygon 19        93 4.30642e+05      5.75e-04\npolygon 20        90 4.15092e+05      5.54e-04\npolygon 21       721 1.92795e+06      2.57e-03\npolygon 22       330 1.11896e+06      1.49e-03\npolygon 23       115 9.28394e+05      1.24e-03\npolygon 24        37 1.01705e+04      1.36e-05\npolygon 25        25 1.66227e+04      2.22e-05\npolygon 26        10 2.14507e+03      2.86e-06\npolygon 27       190 2.02489e+05      2.70e-04\npolygon 28       175 9.25904e+05      1.24e-03\npolygon 29      1993 9.99217e+06      1.33e-02\npolygon 30        38 2.42492e+04      3.24e-05\npolygon 31        24 6.35239e+03      8.48e-06\npolygon 32        53 6.35791e+05      8.49e-04\npolygon 33        41 1.60161e+04      2.14e-05\npolygon 34        22 2.54368e+03      3.40e-06\npolygon 35        30 1.08382e+04      1.45e-05\npolygon 36       327 2.16921e+06      2.90e-03\npolygon 37       111 6.62927e+05      8.85e-04\npolygon 38        90 1.15991e+05      1.55e-04\npolygon 39        98 6.26829e+04      8.37e-05\npolygon 40       415 3.25384e+06      4.35e-03\npolygon 41       222 1.51142e+06      2.02e-03\npolygon 42       107 6.33039e+05      8.45e-04\npolygon 43         7 2.48299e+03      3.32e-06\npolygon 44        17 3.28303e+04      4.38e-05\npolygon 45        26 8.34758e+03      1.11e-05\npolygon 46       177 4.67446e+05      6.24e-04\npolygon 47        16 3.19460e+03      4.27e-06\npolygon 48        15 4.87296e+03      6.51e-06\npolygon 49        66 1.61841e+04      2.16e-05\npolygon 50       149 5.63430e+06      7.53e-03\npolygon 51       609 2.62570e+07      3.51e-02\npolygon 52         8 7.82256e+03      1.04e-05\npolygon 53       976 2.33447e+07      3.12e-02\npolygon 54        55 8.25379e+04      1.10e-04\npolygon 55       976 2.33447e+07      3.12e-02\npolygon 56        61 3.33449e+05      4.45e-04\npolygon 57         6 1.68410e+04      2.25e-05\npolygon 58         4 9.45963e+03      1.26e-05\npolygon 59        46 6.99702e+05      9.35e-04\npolygon 60        13 7.00873e+04      9.36e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 748741000 square units\nFraction of frame area: 0.414\n\n\n\nplot(childcareSG_ppp)"
  },
  {
    "objectID": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#computing-kernal-density-automatically",
    "href": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#computing-kernal-density-automatically",
    "title": "Hands on Excerise 4",
    "section": "6.1 Computing Kernal Density automatically",
    "text": "6.1 Computing Kernal Density automatically\n\nkde_childcareSG_bw <- density(childcareSG_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\n\nplot(kde_childcareSG_bw)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe density of the density is determined in meters, therefore it might be difficult to understand the value\n\n\n\nbw <- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n298.4095"
  },
  {
    "objectID": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#rescalling-kde-value",
    "href": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#rescalling-kde-value",
    "title": "Hands on Excerise 4",
    "section": "6.2 Rescalling KDE Value",
    "text": "6.2 Rescalling KDE Value\n\n\n\n\n\n\nNote\n\n\n\nRescaling help to make the number more understandable to the people.\n\n\n\nchildcareSG_ppp.km <- rescale(childcareSG_ppp, 1000, \"km\")\n\n\nkde_childcareSG.bw <- density(childcareSG_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG.bw)"
  },
  {
    "objectID": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#working-with-different-methods",
    "href": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#working-with-different-methods",
    "title": "Hands on Excerise 4",
    "section": "6.3 Working with different methods",
    "text": "6.3 Working with different methods\n\n bw.CvL(childcareSG_ppp.km)\n\n   sigma \n4.543278 \n\n\n\nbw.scott(childcareSG_ppp.km)\n\n sigma.x  sigma.y \n2.224898 1.450966 \n\n\n\nbw.ppl(childcareSG_ppp.km)\n\n    sigma \n0.3897114 \n\n\n\nbw.diggle(childcareSG_ppp.km)\n\n    sigma \n0.2984095 \n\n\n\nkde_childcareSG.ppl <- density(childcareSG_ppp.km, \n                               sigma=bw.ppl, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")"
  },
  {
    "objectID": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#working-with-different-kernal-methods",
    "href": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#working-with-different-kernal-methods",
    "title": "Hands on Excerise 4",
    "section": "6.4 Working with different kernal methods",
    "text": "6.4 Working with different kernal methods\n\npar(mfrow=c(2,2))\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc\")"
  },
  {
    "objectID": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#computation-using-adaptive-bandwidth",
    "href": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#computation-using-adaptive-bandwidth",
    "title": "Hands on Excerise 4",
    "section": "7.1 Computation using Adaptive Bandwidth",
    "text": "7.1 Computation using Adaptive Bandwidth\n\nkde_childcareSG_adaptive <- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nComparing\n\n\n\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive bandwidth\")"
  },
  {
    "objectID": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#converting-kde-to-grid-object",
    "href": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#converting-kde-to-grid-object",
    "title": "Hands on Excerise 4",
    "section": "7.2 Converting KDE to grid Object",
    "text": "7.2 Converting KDE to grid Object\n\n\n\n\n\n\nNote\n\n\n\nImages is practically useless, therefore we need to convert it into a KDE object.\n\n\n\ngridded_kde_childcareSG_bw <- as.SpatialGridDataFrame.im(kde_childcareSG.bw)\nspplot(gridded_kde_childcareSG_bw)"
  },
  {
    "objectID": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#converting-to-raster-from-grid-object",
    "href": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#converting-to-raster-from-grid-object",
    "title": "Hands on Excerise 4",
    "section": "7.3 Converting to Raster from Grid Object",
    "text": "7.3 Converting to Raster from Grid Object\n\nkde_childcareSG_bw_raster <- raster(gridded_kde_childcareSG_bw)\n\n\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : v \nvalues     : -8.476185e-15, 28.51831  (min, max)"
  },
  {
    "objectID": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#assigning-projection-systems",
    "href": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#assigning-projection-systems",
    "title": "Hands on Excerise 4",
    "section": "7.4 Assigning Projection Systems",
    "text": "7.4 Assigning Projection Systems\n\nprojection(kde_childcareSG_bw_raster) <- CRS(\"+init=EPSG:3414\")\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +init=EPSG:3414 \nsource     : memory\nnames      : v \nvalues     : -8.476185e-15, 28.51831  (min, max)"
  },
  {
    "objectID": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#visualising-in-tmap",
    "href": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#visualising-in-tmap",
    "title": "Hands on Excerise 4",
    "section": "7.5 Visualising in Tmap",
    "text": "7.5 Visualising in Tmap\n\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(\"v\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)##"
  },
  {
    "objectID": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#comparing-spatial-point-pattern",
    "href": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#comparing-spatial-point-pattern",
    "title": "Hands on Excerise 4",
    "section": "7.6 Comparing Spatial Point Pattern",
    "text": "7.6 Comparing Spatial Point Pattern\n\n7.6.1 Extracting the area\n\npg = mpsz[mpsz@data$PLN_AREA_N == \"PUNGGOL\",]\ntm = mpsz[mpsz@data$PLN_AREA_N == \"TAMPINES\",]\nck = mpsz[mpsz@data$PLN_AREA_N == \"CHOA CHU KANG\",]\njw = mpsz[mpsz@data$PLN_AREA_N == \"JURONG WEST\",]\n\n\npar(mfrow=c(2,2))\nplot(pg, main = \"Ponggol\")\nplot(tm, main = \"Tampines\")\nplot(ck, main = \"Choa Chu Kang\")\nplot(jw, main = \"Jurong West\")\n\n\n\n\n\n\n7.6.2 Converting to Generic SP Format\n\npg_sp = as(pg, \"SpatialPolygons\")\ntm_sp = as(tm, \"SpatialPolygons\")\nck_sp = as(ck, \"SpatialPolygons\")\njw_sp = as(jw, \"SpatialPolygons\")\n\n\n\n7.6.3 Creating Owin Object\n\npg_owin = as(pg_sp, \"owin\")\ntm_owin = as(tm_sp, \"owin\")\nck_owin = as(ck_sp, \"owin\")\njw_owin = as(jw_sp, \"owin\")\n\n\n\n7.6.4 Combining Points and Stydu area\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\n\nchildcare_pg_ppp\n\nPlanar point pattern: 61 points\nwindow: polygonal boundary\nenclosing rectangle: [33952.59, 38889.96] x [40874.37, 44808.89] units\n\n\n\nchildcare_pg_ppp.km = rescale(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale(childcare_jw_ppp, 1000, \"km\")\n\n\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp.km, main=\"Punggol\")\nplot(childcare_tm_ppp.km, main=\"Tampines\")\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\nplot(childcare_jw_ppp.km, main=\"Jurong West\")\n\n\n\n\n\n\n7.6.5 Computing KDE\n\npar(mfrow=c(2,2))\nplot(density(childcare_pg_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tempines\")\nplot(density(childcare_ck_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"JUrong West\")\n\n\n\n\n\npar(mfrow=c(2,2))\nplot(density(childcare_ck_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Chou Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"JUrong West\")\nplot(density(childcare_pg_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")"
  },
  {
    "objectID": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#testing-with-clar-and-evans",
    "href": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#testing-with-clar-and-evans",
    "title": "Hands on Excerise 4",
    "section": "8.1 Testing with Clar and Evans",
    "text": "8.1 Testing with Clar and Evans\n\nclarkevans.test(childcareSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Monte Carlo test based on 99 simulations of CSR with fixed n\n\ndata:  childcareSG_ppp\nR = 0.54756, p-value = 0.01\nalternative hypothesis: clustered (R < 1)\n\n\n\n\n\n\n\n\nNote\n\n\n\nPossible Conclusion that it might not be randomly distributed."
  },
  {
    "objectID": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#clark-and-evans-test-on-cck-planning-area",
    "href": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#clark-and-evans-test-on-cck-planning-area",
    "title": "Hands on Excerise 4",
    "section": "8.2 Clark and Evans Test On CCK Planning Area",
    "text": "8.2 Clark and Evans Test On CCK Planning Area\n\nclarkevans.test(childcare_ck_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Monte Carlo test based on 999 simulations of CSR with fixed n\n\ndata:  childcare_ck_ppp\nR = 0.93503, p-value = 0.096\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#clark-and-evans-test-on-tampinese-planning-area",
    "href": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#clark-and-evans-test-on-tampinese-planning-area",
    "title": "Hands on Excerise 4",
    "section": "8.3 Clark and Evans Test On Tampinese Planning Area",
    "text": "8.3 Clark and Evans Test On Tampinese Planning Area\n\nclarkevans.test(childcare_tm_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Monte Carlo test based on 999 simulations of CSR with fixed n\n\ndata:  childcare_tm_ppp\nR = 0.79355, p-value = 0.002\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#choa-chu-kang-area",
    "href": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#choa-chu-kang-area",
    "title": "Hands on Excerise 4",
    "section": "9.1 Choa Chu Kang Area",
    "text": "9.1 Choa Chu Kang Area\n\n9.1.1 Computing G Function estimation\n\nG_CK = Gest(childcare_ck_ppp, correction = \"border\")\nplot(G_CK, xlim=c(0,500))\n\n\n\n\n\n\n9.1.2 Performing Complete Spatial Randomness Test\n\nG_CK.csr <- envelope(childcare_ck_ppp, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60........\n.70.........80.........90.........100.........110.........120.........130......\n...140.........150.........160.........170.........180.........190.........200....\n.....210.........220.........230.........240.........250.........260.........270..\n.......280.........290.........300.........310.........320.........330.........340\n.........350.........360.........370.........380.........390.........400........\n.410.........420.........430.........440.........450.........460.........470......\n...480.........490.........500.........510.........520.........530.........540....\n.....550.........560.........570.........580.........590.........600.........610..\n.......620.........630.........640.........650.........660.........670.........680\n.........690.........700.........710.........720.........730.........740........\n.750.........760.........770.........780.........790.........800.........810......\n...820.........830.........840.........850.........860.........870.........880....\n.....890.........900.........910.........920.........930.........940.........950..\n.......960.........970.........980.........990........ 999.\n\nDone.\n\n\n\nplot(G_CK.csr)"
  },
  {
    "objectID": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#tampinese-planning-area",
    "href": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#tampinese-planning-area",
    "title": "Hands on Excerise 4",
    "section": "9.2 Tampinese Planning Area",
    "text": "9.2 Tampinese Planning Area\n\n9.2.1 Computing G Function\n\nG_tm = Gest(childcare_tm_ppp, correction = \"best\")\nplot(G_tm)\n\n\n\n\n\n\n9.2.2 Performing Complete Spatial Randomness Test\n\nG_tm.csr <- envelope(childcare_tm_ppp, Gest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60........\n.70.........80.........90.........100.........110.........120.........130......\n...140.........150.........160.........170.........180.........190.........200....\n.....210.........220.........230.........240.........250.........260.........270..\n.......280.........290.........300.........310.........320.........330.........340\n.........350.........360.........370.........380.........390.........400........\n.410.........420.........430.........440.........450.........460.........470......\n...480.........490.........500.........510.........520.........530.........540....\n.....550.........560.........570.........580.........590.........600.........610..\n.......620.........630.........640.........650.........660.........670.........680\n.........690.........700.........710.........720.........730.........740........\n.750.........760.........770.........780.........790.........800.........810......\n...820.........830.........840.........850.........860.........870.........880....\n.....890.........900.........910.........920.........930.........940.........950..\n.......960.........970.........980.........990........ 999.\n\nDone.\n\n\n\nplot(G_tm.csr)"
  },
  {
    "objectID": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#choa-chu-kang",
    "href": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#choa-chu-kang",
    "title": "Hands on Excerise 4",
    "section": "10.1 Choa Chu Kang",
    "text": "10.1 Choa Chu Kang\n\n10.1.1 Computing F Function Estimate\n\nF_CK = Fest(childcare_ck_ppp)\nplot(F_CK)\n\n\n\n\n\n\n10.1.2 Complete Spatial Randomness Test\n\nF_CK.csr <- envelope(childcare_ck_ppp, Fest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60........\n.70.........80.........90.........100.........110.........120.........130......\n...140.........150.........160.........170.........180.........190.........200....\n.....210.........220.........230.........240.........250.........260.........270..\n.......280.........290.........300.........310.........320.........330.........340\n.........350.........360.........370.........380.........390.........400........\n.410.........420.........430.........440.........450.........460.........470......\n...480.........490.........500.........510.........520.........530.........540....\n.....550.........560.........570.........580.........590.........600.........610..\n.......620.........630.........640.........650.........660.........670.........680\n.........690.........700.........710.........720.........730.........740........\n.750.........760.........770.........780.........790.........800.........810......\n...820.........830.........840.........850.........860.........870.........880....\n.....890.........900.........910.........920.........930.........940.........950..\n.......960.........970.........980.........990........ 999.\n\nDone.\n\n\n\nplot(F_CK.csr)"
  },
  {
    "objectID": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#tampines",
    "href": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#tampines",
    "title": "Hands on Excerise 4",
    "section": "10.2 Tampines",
    "text": "10.2 Tampines\n\n10.2.1 Computing F Function Estimate\n\nF_tm = Fest(childcare_tm_ppp, correction = \"best\")\nplot(F_tm)\n\n\n\n\n\n\n10.2.2 Complete Spatial Randomness Test\n\nF_tm.csr <- envelope(childcare_tm_ppp, Fest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60........\n.70.........80.........90.........100.........110.........120.........130......\n...140.........150.........160.........170.........180.........190.........200....\n.....210.........220.........230.........240.........250.........260.........270..\n.......280.........290.........300.........310.........320.........330.........340\n.........350.........360.........370.........380.........390.........400........\n.410.........420.........430.........440.........450.........460.........470......\n...480.........490.........500.........510.........520.........530.........540....\n.....550.........560.........570.........580.........590.........600.........610..\n.......620.........630.........640.........650.........660.........670.........680\n.........690.........700.........710.........720.........730.........740........\n.750.........760.........770.........780.........790.........800.........810......\n...820.........830.........840.........850.........860.........870.........880....\n.....890.........900.........910.........920.........930.........940.........950..\n.......960.........970.........980.........990........ 999.\n\nDone.\n\n\n\nplot(F_tm.csr)"
  },
  {
    "objectID": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#choa-chu-kang-1",
    "href": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#choa-chu-kang-1",
    "title": "Hands on Excerise 4",
    "section": "11.1 Choa Chu Kang",
    "text": "11.1 Choa Chu Kang\n\n11.1.1 Computing K Function Estimate\n\nK_ck = Kest(childcare_ck_ppp, correction = \"Ripley\")\nplot(K_ck, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n11.1.2 Complete Spatial Randomness Test\n\nK_ck.csr <- envelope(childcare_ck_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98,  99.\n\nDone.\n\n\n\nplot(K_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")"
  },
  {
    "objectID": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#tampines-1",
    "href": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#tampines-1",
    "title": "Hands on Excerise 4",
    "section": "11.2 Tampines",
    "text": "11.2 Tampines\n\n11.2.1 Computing K Function Estimate\n\nK_tm = Kest(childcare_tm_ppp, correction = \"Ripley\")\nplot(K_tm, . -r ~ r, \n     ylab= \"K(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n11.2.2 Complete Spatial Randomness Test\n\nK_tm.csr <- envelope(childcare_tm_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98,  99.\n\nDone.\n\n\n\nplot(K_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"K(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#choa-chu-kang-2",
    "href": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#choa-chu-kang-2",
    "title": "Hands on Excerise 4",
    "section": "12.1 Choa Chu Kang",
    "text": "12.1 Choa Chu Kang\n\n12.1.1 Computing L Function Estimate\n\n\n\n\n\n\nNote\n\n\n\nThis is a plot without simulation, therefore this is an estimate.\nCorrection extends the boundary so that we can see more the point at the edge.\n\n\n\nL_ck = Lest(childcare_ck_ppp, correction = \"Ripley\")\nplot(L_ck, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n12.1.2 Complete Spatial Randomness Test\n\n\n\n\n\n\nNote\n\n\n\nThe envelope method perform the monte carlo simulation of the point. the number of simulation is based on the confidence level.\n\n\n\nL_ck.csr <- envelope(childcare_ck_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98,  99.\n\nDone.\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nBased on the graph below. As long as the line is below boundary, it is statistically insignificant. In the Prof example, the distance between 480 and 580, is statistically significant to proof that there is clustering\n\n\n\nplot(L_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")"
  },
  {
    "objectID": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#tampines-2",
    "href": "lessons/Hands-on/Hands-on-Ex4/Hands-on-Ex4.html#tampines-2",
    "title": "Hands on Excerise 4",
    "section": "12.2 Tampines",
    "text": "12.2 Tampines\n\n12.2.1 Computing L Function Estimate\n\nL_tm = Lest(childcare_tm_ppp, correction = \"Ripley\")\nplot(L_tm, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n12.2.2 Complete Spatial Randomness Test\n\nL_tm.csr <- envelope(childcare_tm_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98,  99.\n\nDone.\n\n\n\nplot(L_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"L(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "lessons/In-class/in-class_ex8/In-class_Ex08.html",
    "href": "lessons/In-class/in-class_ex8/In-class_Ex08.html",
    "title": "In Class Exercise 8",
    "section": "",
    "text": "Important\n\n\n\nWe will be using sfdep in In-Class-Excercise instead of spded in Hands On Excercise"
  },
  {
    "objectID": "lessons/In-class/in-class_ex8/In-class_Ex08.html#importing-the-geospatial-data",
    "href": "lessons/In-class/in-class_ex8/In-class_Ex08.html#importing-the-geospatial-data",
    "title": "In Class Exercise 8",
    "section": "2.1 Importing the Geospatial data",
    "text": "2.1 Importing the Geospatial data\n\n\n\n\n\n\nNote\n\n\n\nThis file is loaded as a sf dataframe\n\n\n\nmpsz = st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\hxchen-2019\\birdie\\lessons\\In-class\\in-class_ex8\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nmpsz_svy21 <- st_transform(mpsz, 3414)"
  },
  {
    "objectID": "lessons/In-class/in-class_ex8/In-class_Ex08.html#update-the-crs-model",
    "href": "lessons/In-class/in-class_ex8/In-class_Ex08.html#update-the-crs-model",
    "title": "In Class Exercise 8",
    "section": "2.2 Update the CRS Model",
    "text": "2.2 Update the CRS Model\n\nst_crs(mpsz_svy21)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\nst_bbox(mpsz) #view extent\n\n     xmin      ymin      xmax      ymax \n 2667.538 15748.721 56396.440 50256.334"
  },
  {
    "objectID": "lessons/In-class/in-class_ex8/In-class_Ex08.html#reading-the-aspatial-data",
    "href": "lessons/In-class/in-class_ex8/In-class_Ex08.html#reading-the-aspatial-data",
    "title": "In Class Exercise 8",
    "section": "2.3 Reading the Aspatial Data",
    "text": "2.3 Reading the Aspatial Data\n\ncondo_resale = readr::read_csv(\"data/aspatial/Condo_resale_2015.csv\")\n\n\ndplyr::glimpse(condo_resale)\n\nRows: 1,436\nColumns: 23\n$ LATITUDE             <dbl> 1.287145, 1.328698, 1.313727, 1.308563, 1.321437,…\n$ LONGITUDE            <dbl> 103.7802, 103.8123, 103.7971, 103.8247, 103.9505,…\n$ POSTCODE             <dbl> 118635, 288420, 267833, 258380, 467169, 466472, 3…\n$ SELLING_PRICE        <dbl> 3000000, 3880000, 3325000, 4250000, 1400000, 1320…\n$ AREA_SQM             <dbl> 309, 290, 248, 127, 145, 139, 218, 141, 165, 168,…\n$ AGE                  <dbl> 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22, 6,…\n$ PROX_CBD             <dbl> 7.941259, 6.609797, 6.898000, 4.038861, 11.783402…\n$ PROX_CHILDCARE       <dbl> 0.16597932, 0.28027246, 0.42922669, 0.39473543, 0…\n$ PROX_ELDERLYCARE     <dbl> 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.121…\n$ PROX_URA_GROWTH_AREA <dbl> 6.618741, 7.505109, 6.463887, 4.906512, 6.410632,…\n$ PROX_HAWKER_MARKET   <dbl> 1.76542207, 0.54507614, 0.37789301, 1.68259969, 0…\n$ PROX_KINDERGARTEN    <dbl> 0.05835552, 0.61592412, 0.14120309, 0.38200076, 0…\n$ PROX_MRT             <dbl> 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.528…\n$ PROX_PARK            <dbl> 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.116…\n$ PROX_PRIMARY_SCH     <dbl> 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.709…\n$ PROX_TOP_PRIMARY_SCH <dbl> 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.709…\n$ PROX_SHOPPING_MALL   <dbl> 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.307…\n$ PROX_SUPERMARKET     <dbl> 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.581…\n$ PROX_BUS_STOP        <dbl> 0.10336166, 0.28673408, 0.28504777, 0.29872340, 0…\n$ NO_Of_UNITS          <dbl> 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34, 3…\n$ FAMILY_FRIENDLY      <dbl> 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD             <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\n\nsummary(condo_resale)\n\n    LATITUDE       LONGITUDE        POSTCODE      SELLING_PRICE     \n Min.   :1.240   Min.   :103.7   Min.   : 18965   Min.   :  540000  \n 1st Qu.:1.309   1st Qu.:103.8   1st Qu.:259849   1st Qu.: 1100000  \n Median :1.328   Median :103.8   Median :469298   Median : 1383222  \n Mean   :1.334   Mean   :103.8   Mean   :440439   Mean   : 1751211  \n 3rd Qu.:1.357   3rd Qu.:103.9   3rd Qu.:589486   3rd Qu.: 1950000  \n Max.   :1.454   Max.   :104.0   Max.   :828833   Max.   :18000000  \n    AREA_SQM          AGE           PROX_CBD       PROX_CHILDCARE    \n Min.   : 34.0   Min.   : 0.00   Min.   : 0.3869   Min.   :0.004927  \n 1st Qu.:103.0   1st Qu.: 5.00   1st Qu.: 5.5574   1st Qu.:0.174481  \n Median :121.0   Median :11.00   Median : 9.3567   Median :0.258135  \n Mean   :136.5   Mean   :12.14   Mean   : 9.3254   Mean   :0.326313  \n 3rd Qu.:156.0   3rd Qu.:18.00   3rd Qu.:12.6661   3rd Qu.:0.368293  \n Max.   :619.0   Max.   :37.00   Max.   :19.1804   Max.   :3.465726  \n PROX_ELDERLYCARE  PROX_URA_GROWTH_AREA PROX_HAWKER_MARKET PROX_KINDERGARTEN \n Min.   :0.05451   Min.   :0.2145       Min.   :0.05182    Min.   :0.004927  \n 1st Qu.:0.61254   1st Qu.:3.1643       1st Qu.:0.55245    1st Qu.:0.276345  \n Median :0.94179   Median :4.6186       Median :0.90842    Median :0.413385  \n Mean   :1.05351   Mean   :4.5981       Mean   :1.27987    Mean   :0.458903  \n 3rd Qu.:1.35122   3rd Qu.:5.7550       3rd Qu.:1.68578    3rd Qu.:0.578474  \n Max.   :3.94916   Max.   :9.1554       Max.   :5.37435    Max.   :2.229045  \n    PROX_MRT         PROX_PARK       PROX_PRIMARY_SCH  PROX_TOP_PRIMARY_SCH\n Min.   :0.05278   Min.   :0.02906   Min.   :0.07711   Min.   :0.07711     \n 1st Qu.:0.34646   1st Qu.:0.26211   1st Qu.:0.44024   1st Qu.:1.34451     \n Median :0.57430   Median :0.39926   Median :0.63505   Median :1.88213     \n Mean   :0.67316   Mean   :0.49802   Mean   :0.75471   Mean   :2.27347     \n 3rd Qu.:0.84844   3rd Qu.:0.65592   3rd Qu.:0.95104   3rd Qu.:2.90954     \n Max.   :3.48037   Max.   :2.16105   Max.   :3.92899   Max.   :6.74819     \n PROX_SHOPPING_MALL PROX_SUPERMARKET PROX_BUS_STOP       NO_Of_UNITS    \n Min.   :0.0000     Min.   :0.0000   Min.   :0.001595   Min.   :  18.0  \n 1st Qu.:0.5258     1st Qu.:0.3695   1st Qu.:0.098356   1st Qu.: 188.8  \n Median :0.9357     Median :0.5687   Median :0.151710   Median : 360.0  \n Mean   :1.0455     Mean   :0.6141   Mean   :0.193974   Mean   : 409.2  \n 3rd Qu.:1.3994     3rd Qu.:0.7862   3rd Qu.:0.220466   3rd Qu.: 590.0  \n Max.   :3.4774     Max.   :2.2441   Max.   :2.476639   Max.   :1703.0  \n FAMILY_FRIENDLY     FREEHOLD      LEASEHOLD_99YR  \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :0.0000  \n Mean   :0.4868   Mean   :0.4227   Mean   :0.4882  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n\n\n\n2.3.1 Converting aspatial dataframe into a sf object\n\ncondo_resale.sf <- st_as_sf(condo_resale,\n                            coords = c(\"LONGITUDE\", \"LATITUDE\"),\n                            crs=4326) %>%\n  st_transform(crs=3414)"
  },
  {
    "objectID": "lessons/In-class/in-class_ex8/In-class_Ex08.html#multiple-histogram-plots",
    "href": "lessons/In-class/in-class_ex8/In-class_Ex08.html#multiple-histogram-plots",
    "title": "In Class Exercise 8",
    "section": "3.1 Multiple Histogram Plots",
    "text": "3.1 Multiple Histogram Plots\n\n## Need to fix all of t\n\n\n3.1.1 Drawing Statistical Point Map\n\ntmap_mode(\"view\")\n\n\ntm_shape(mpsz_svy21)+\n  tm_polygons() +\ntm_shape(condo_resale.sf) +  \n  tmap_options(check.and.fix = TRUE)+\n  tm_dots(\n          col = \"SELLING_PRICE\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\n\n\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "lessons/In-class/in-class_ex8/In-class_Ex08.html#simple-linear-regression",
    "href": "lessons/In-class/in-class_ex8/In-class_Ex08.html#simple-linear-regression",
    "title": "In Class Exercise 8",
    "section": "4.1 Simple Linear Regression",
    "text": "4.1 Simple Linear Regression\n\ncondo.slr <- lm(formula=SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nWe will plot it to see\n\n## Need to fix thios"
  },
  {
    "objectID": "lessons/In-class/in-class_ex8/In-class_Ex08.html#multiple-linear-regression",
    "href": "lessons/In-class/in-class_ex8/In-class_Ex08.html#multiple-linear-regression",
    "title": "In Class Exercise 8",
    "section": "4.2 Multiple Linear Regression",
    "text": "4.2 Multiple Linear Regression\nWe need to check the correlation first\n\ncorrplot::corrplot(cor(condo_resale[, 5:23]), diag = FALSE, order = \"AOE\",\n         tl.pos = \"td\", tl.cex = 0.5, method = \"number\", type = \"upper\")"
  },
  {
    "objectID": "lessons/In-class/in-class_ex8/In-class_Ex08.html#building-a-hedonic-pricing-model-using-multiple-linear-regression-method",
    "href": "lessons/In-class/in-class_ex8/In-class_Ex08.html#building-a-hedonic-pricing-model-using-multiple-linear-regression-method",
    "title": "In Class Exercise 8",
    "section": "4.3 Building a hedonic pricing model using multiple linear regression method",
    "text": "4.3 Building a hedonic pricing model using multiple linear regression method\n\ncondo.mlr <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE    + \n                  PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                  PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + \n                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + \n                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n                  PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                data=condo_resale.sf)\nsummary(condo.mlr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3475964  -293923   -23069   241043 12260381 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(>|t|)    \n(Intercept)           481728.40  121441.01   3.967 7.65e-05 ***\nAREA_SQM               12708.32     369.59  34.385  < 2e-16 ***\nAGE                   -24440.82    2763.16  -8.845  < 2e-16 ***\nPROX_CBD              -78669.78    6768.97 -11.622  < 2e-16 ***\nPROX_CHILDCARE       -351617.91  109467.25  -3.212  0.00135 ** \nPROX_ELDERLYCARE      171029.42   42110.51   4.061 5.14e-05 ***\nPROX_URA_GROWTH_AREA   38474.53   12523.57   3.072  0.00217 ** \nPROX_HAWKER_MARKET     23746.10   29299.76   0.810  0.41782    \nPROX_KINDERGARTEN     147468.99   82668.87   1.784  0.07466 .  \nPROX_MRT             -314599.68   57947.44  -5.429 6.66e-08 ***\nPROX_PARK             563280.50   66551.68   8.464  < 2e-16 ***\nPROX_PRIMARY_SCH      180186.08   65237.95   2.762  0.00582 ** \nPROX_TOP_PRIMARY_SCH    2280.04   20410.43   0.112  0.91107    \nPROX_SHOPPING_MALL   -206604.06   42840.60  -4.823 1.57e-06 ***\nPROX_SUPERMARKET      -44991.80   77082.64  -0.584  0.55953    \nPROX_BUS_STOP         683121.35  138353.28   4.938 8.85e-07 ***\nNO_Of_UNITS             -231.18      89.03  -2.597  0.00951 ** \nFAMILY_FRIENDLY       140340.77   47020.55   2.985  0.00289 ** \nFREEHOLD              359913.01   49220.22   7.312 4.38e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 755800 on 1417 degrees of freedom\nMultiple R-squared:  0.6518,    Adjusted R-squared:  0.6474 \nF-statistic: 147.4 on 18 and 1417 DF,  p-value: < 2.2e-16\n\n\n\n4.3.1 Preparing Publication Quality Table\n\ncondo.mlr1 <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                   PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                   PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK + \n                   PROX_PRIMARY_SCH + PROX_SHOPPING_MALL    + PROX_BUS_STOP + \n                   NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,\n                 data=condo_resale.sf)\nols_regress(condo.mlr1)\n\n                             Model Summary                               \n------------------------------------------------------------------------\nR                       0.807       RMSE                     755957.289 \nR-Squared               0.651       Coef. Var                    43.168 \nAdj. R-Squared          0.647       MSE                571471422208.591 \nPred R-Squared          0.638       MAE                      414819.628 \n------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.512586e+15          14        1.080418e+14    189.059    0.0000 \nResidual      8.120609e+14        1421    571471422208.591                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     527633.222    108183.223                   4.877    0.000     315417.244     739849.200 \n            AREA_SQM      12777.523       367.479        0.584     34.771    0.000      12056.663      13498.382 \n                 AGE     -24687.739      2754.845       -0.167     -8.962    0.000     -30091.739     -19283.740 \n            PROX_CBD     -77131.323      5763.125       -0.263    -13.384    0.000     -88436.469     -65826.176 \n      PROX_CHILDCARE    -318472.751    107959.512       -0.084     -2.950    0.003    -530249.889    -106695.613 \n    PROX_ELDERLYCARE     185575.623     39901.864        0.090      4.651    0.000     107302.737     263848.510 \nPROX_URA_GROWTH_AREA      39163.254     11754.829        0.060      3.332    0.001      16104.571      62221.936 \n            PROX_MRT    -294745.107     56916.367       -0.112     -5.179    0.000    -406394.234    -183095.980 \n           PROX_PARK     570504.807     65507.029        0.150      8.709    0.000     442003.938     699005.677 \n    PROX_PRIMARY_SCH     159856.136     60234.599        0.062      2.654    0.008      41697.849     278014.424 \n  PROX_SHOPPING_MALL    -220947.251     36561.832       -0.115     -6.043    0.000    -292668.213    -149226.288 \n       PROX_BUS_STOP     682482.221    134513.243        0.134      5.074    0.000     418616.359     946348.082 \n         NO_Of_UNITS       -245.480        87.947       -0.053     -2.791    0.005       -418.000        -72.961 \n     FAMILY_FRIENDLY     146307.576     46893.021        0.057      3.120    0.002      54320.593     238294.560 \n            FREEHOLD     350599.812     48506.485        0.136      7.228    0.000     255447.802     445751.821 \n-----------------------------------------------------------------------------------------------------------------\n\n\n\n\n4.3.2 Preparing using GT SUmamry\n\ntbl_regression(condo.mlr1, intercept = TRUE)\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n<0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n<0.001\n    AGE\n-24,688\n-30,092, -19,284\n<0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n<0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n<0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n<0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n<0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n<0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n<0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n<0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n<0.001\n  \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\n\n\n4.3.3 Regression\n\ntbl_regression(condo.mlr1, \n               intercept = TRUE) %>% \n  add_glance_source_note(\n    label = list(sigma ~ \"\\U03C3\"),\n    include = c(r.squared, adj.r.squared, \n                AIC, statistic,\n                p.value, sigma))\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n<0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n<0.001\n    AGE\n-24,688\n-30,092, -19,284\n<0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n<0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n<0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n<0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n<0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n<0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n<0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n<0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n<0.001\n  \n  \n    \n      R² = 0.651; Adjusted R² = 0.647; AIC = 42,967; Statistic = 189; p-value = <0.001; σ = 755,957\n    \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\n\n\n4.3.4 CHecking for multicolinearity\n\nols_vif_tol(condo.mlr1)\n\n              Variables Tolerance      VIF\n1              AREA_SQM 0.8728554 1.145665\n2                   AGE 0.7071275 1.414172\n3              PROX_CBD 0.6356147 1.573280\n4        PROX_CHILDCARE 0.3066019 3.261559\n5      PROX_ELDERLYCARE 0.6598479 1.515501\n6  PROX_URA_GROWTH_AREA 0.7510311 1.331503\n7              PROX_MRT 0.5236090 1.909822\n8             PROX_PARK 0.8279261 1.207837\n9      PROX_PRIMARY_SCH 0.4524628 2.210126\n10   PROX_SHOPPING_MALL 0.6738795 1.483945\n11        PROX_BUS_STOP 0.3514118 2.845664\n12          NO_Of_UNITS 0.6901036 1.449058\n13      FAMILY_FRIENDLY 0.7244157 1.380423\n14             FREEHOLD 0.6931163 1.442759"
  },
  {
    "objectID": "lessons/Take-home/Take-home_ex2/Take-home_ex2.html",
    "href": "lessons/Take-home/Take-home_ex2/Take-home_ex2.html",
    "title": "Take Home Exercise 2",
    "section": "",
    "text": "Important\n\n\n\nThis part is taken from IS415 Take Home Exercise 2. All rights belong to Dr Kam Tin Seong.\n\n\nSince late December 2019, an outbreak of a novel coronavirus disease (COVID-19; previously known as 2019-nCoV) was reported in Wuhan, China, which had subsequently affected 210 countries worldwide. In general, COVID-19 is an acute resolved disease but it can also be deadly, with a 2% case fatality rate.\nThe COVID-19 vaccination in Indonesia is an ongoing mass immunisation in response to the COVID-19 pandemic in Indonesia. On 13 January 2021, the program commenced when President Joko Widodo was vaccinated at the presidential palace. In terms of total doses given, Indonesia ranks third in Asia and fifth in the world.\nAccording to wikipedia, as of 5 February 2023 at 18:00 WIB (UTC+7), 204,266,655 people had received the first dose of the vaccine and 175,131,893 people had been fully vaccinated; 69,597,474 of them had been inoculated with the booster or the third dose, while 1,585,164 had received the fourth dose. Jakarta has the highest percentage of population fully vaccinated with 103.46%, followed by Bali and Special Region of Yogyakarta with 85.45% and 83.02% respectively.\nDespite its compactness, the cumulative vaccination rate are not evenly distributed within DKI Jakarta. The question is where are the sub-districts with relatively higher number of vaccination rate and how they changed over time."
  },
  {
    "objectID": "lessons/Take-home/Take-home_ex2/Take-home_ex2.html#getting-the-data",
    "href": "lessons/Take-home/Take-home_ex2/Take-home_ex2.html#getting-the-data",
    "title": "Take Home Exercise 2",
    "section": "Getting the Data",
    "text": "Getting the Data\nIn this Take Home Exercise, the main dataset we will be using would be indicated here:\n\nAspatial Data: We will be making use of the data from Riwayat File Vaksinasi DKI Jakarta. This website the vaccination data set for Jakarta. Based on the task, I have downloaded the data set from the month of July 2021 to June 2022. For this analysis, I have decided to pick the 1st Day of the Month.\nGeospatial Data: We will be making use of the DKI Jakarta administration boundary from 2019 in this case. The data can be found here."
  },
  {
    "objectID": "lessons/Take-home/Take-home_ex2/Take-home_ex2.html#analyzing-the-data",
    "href": "lessons/Take-home/Take-home_ex2/Take-home_ex2.html#analyzing-the-data",
    "title": "Take Home Exercise 2",
    "section": "Analyzing the Data",
    "text": "Analyzing the Data\n\nAspatial Data\nNow that we have gotten the data set, lets take a look at the data set. We will start off by loading the dataset from month of July 2021 first.\n\nJuly_2021 <- read_excel(\"data/aspatial/Data Vaksinasi Berbasis Kelurahan (01 Juli 2021).xlsx\")\n\n\nJuly_2021\n\n# A tibble: 268 × 21\n   KODE KELURA…¹ WILAY…² KECAM…³ KELUR…⁴ SASARAN BELUM…⁵ JUMLA…⁶ JUMLA…⁷ TOTAL…⁸\n   <chr>         <chr>   <chr>   <chr>     <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1 <NA>          <NA>    <NA>    TOTAL   7739060 5041111 2696017 1181740 3877757\n 2 3172051003    JAKART… PADEMA… ANCOL     20393   13272    7114    3287   10401\n 3 3173041007    JAKART… TAMBORA ANGKE     25785   16477    9299    3221   12520\n 4 3175041005    JAKART… KRAMAT… BALE K…   25158   18849    6301    2644    8945\n 5 3175031003    JAKART… JATINE… BALI M…    8683    5743    2937    1517    4454\n 6 3175101006    JAKART… CIPAYU… BAMBU …   22768   15407    7357    3985   11342\n 7 3174031002    JAKART… MAMPAN… BANGKA    18930   12503    6421    2704    9125\n 8 3175051002    JAKART… PASAR … BARU      20267   11268    8982    4674   13656\n 9 3175041004    JAKART… KRAMAT… BATU A…   41389   30358   11020    5254   16274\n10 3171071002    JAKART… TANAH … BENDUN…   19008   11502    7499    3566   11065\n# … with 258 more rows, 12 more variables: `LANSIA\\r\\nDOSIS 1` <dbl>,\n#   `LANSIA\\r\\nDOSIS 2` <dbl>, `LANSIA TOTAL \\r\\nVAKSIN DIBERIKAN` <dbl>,\n#   `PELAYAN PUBLIK\\r\\nDOSIS 1` <dbl>, `PELAYAN PUBLIK\\r\\nDOSIS 2` <dbl>,\n#   `PELAYAN PUBLIK TOTAL\\r\\nVAKSIN DIBERIKAN` <dbl>,\n#   `GOTONG ROYONG\\r\\nDOSIS 1` <dbl>, `GOTONG ROYONG\\r\\nDOSIS 2` <dbl>,\n#   `GOTONG ROYONG TOTAL\\r\\nVAKSIN DIBERIKAN` <dbl>,\n#   `TENAGA KESEHATAN\\r\\nDOSIS 1` <dbl>, `TENAGA KESEHATAN\\r\\nDOSIS 2` <dbl>, …\n\n\nBased on what we can see, we have noticed that the data set is written in Indonesian. In this exercise, I am only interested in the first 6 columns, of which a rough translation of what each columns means is given in the table below.\n\n\n\nIndonesian Name\nRough Translation\n\n\n\n\nKODE KELURAHAN\nVillage Code\n\n\nWILAYAH KOTA\nCity Area (ADM2)\n\n\nKECAMATAN\nDistrict (ADM3)\n\n\nKELURAHAN\nUrban Village\n\n\nSASARAN\nTarget\n\n\nBELUM VAKSIN\nNot Vaccinated\n\n\n\nFurthermore, note that there is actually a row in the data frame that provides only the total count, we would need to drop the row as well. I have check through the rest of the data set and found that they are all in the same format as above, as such we can perform the same code for all the data.\nThe Code Chunk below show how we can perform all the filtering and the removal of the first row in a single code chunk\n\nJuly_2021 <- read_excel(\"data/aspatial/Data Vaksinasi Berbasis Kelurahan (01 Juli 2021).xlsx\") %>% \n  select(0:6) %>%\n  filter(!row_number() %in% c(1))\n\nWe can then verify that it has been removed already.\n\nJuly_2021\n\n# A tibble: 267 × 6\n   `KODE KELURAHAN` `WILAYAH KOTA`  KECAMATAN        KELURAHAN   SASARAN BELUM…¹\n   <chr>            <chr>           <chr>            <chr>         <dbl>   <dbl>\n 1 3172051003       JAKARTA UTARA   PADEMANGAN       ANCOL         20393   13272\n 2 3173041007       JAKARTA BARAT   TAMBORA          ANGKE         25785   16477\n 3 3175041005       JAKARTA TIMUR   KRAMAT JATI      BALE KAMBA…   25158   18849\n 4 3175031003       JAKARTA TIMUR   JATINEGARA       BALI MESTER    8683    5743\n 5 3175101006       JAKARTA TIMUR   CIPAYUNG         BAMBU APUS    22768   15407\n 6 3174031002       JAKARTA SELATAN MAMPANG PRAPATAN BANGKA        18930   12503\n 7 3175051002       JAKARTA TIMUR   PASAR REBO       BARU          20267   11268\n 8 3175041004       JAKARTA TIMUR   KRAMAT JATI      BATU AMPAR    41389   30358\n 9 3171071002       JAKARTA PUSAT   TANAH ABANG      BENDUNGAN …   19008   11502\n10 3175031002       JAKARTA TIMUR   JATINEGARA       BIDARA CINA   32331   23395\n# … with 257 more rows, and abbreviated variable name ¹​`BELUM VAKSIN`\n\n\n\n\nGeospatial Data\nNow that we had taken a look at the Aspatial Data, we can take a look at the Geospatial Data.\nWe will import the Jakarta into a sf data frame with the code chunk below. In order to ensure that the spatial data is accurate, we would need to use the apply the correct crs information to the sf data frame through st_transform. As we are focusing on Jakarta, the CRS code is 23845. Find out more about Indonesia CRS here.\n\nJakarta_Area <- st_read(dsn = \"data/geospatial\", \n                 layer = \"BATAS_DESA_DESEMBER_2019_DUKCAPIL_DKI_JAKARTA\") %>%\n  st_transform(crs = 23845)\n\nReading layer `BATAS_DESA_DESEMBER_2019_DUKCAPIL_DKI_JAKARTA' from data source \n  `C:\\hxchen-2019\\birdie\\lessons\\Take-home\\Take-home_ex2\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 269 features and 161 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 106.3831 ymin: -6.370815 xmax: 106.9728 ymax: -5.184322\nGeodetic CRS:  WGS 84\n\n\nLets take a look at the data frame first. One thing you have noted is that there is a total of 162 columns in the sf data frame, and most of which is redundant in our current analysis. In this case, we are only interested in the first 9 columns of the sf data frame. The details of the data frame is as provided below:\n\n\n\nColumn Name\nRough Translation\n\n\n\n\nOBJECT_ID\nobject id\n\n\nKODE_DESA\nVillage Code\n\n\nDESA\nVillage - Similar to Urban Village\n\n\nKODE\nCode\n\n\nPROVINSI\nProvince\n\n\nKAB_KOTA\nCity District (ADM2) - Similar to City Area\n\n\nKECAMATAN\nDistrict (ADM3)\n\n\nDESA_KELAR\nVillage\n\n\nJUMLAH_PEN\nPopulations\n\n\n\nAnother important point to note is that while our Vaccination Data Frame only has 267 observations as compared to our sf data frame having 269 observations, this would mean that there is 2 extra areas in the sf data frame that we need to handle.\nUpon closer look at the data, we found out that there are 2 areas in the sf data frame that has no data, those areas are:\n\nDANAU SUNTER\nDANAU SUNTER DLL\n\nWe could just drops the rows as they have no meaningful data, but we might want to take a look more closely first. To solve the issue first we will extract filter the relevant data from the sf data set first, through the code chunk below.\n\nJakarta_Area <- st_read(dsn = \"data/geospatial\", \n                 layer = \"BATAS_DESA_DESEMBER_2019_DUKCAPIL_DKI_JAKARTA\") %>%\n  select(0:9)\n\nReading layer `BATAS_DESA_DESEMBER_2019_DUKCAPIL_DKI_JAKARTA' from data source \n  `C:\\hxchen-2019\\birdie\\lessons\\Take-home\\Take-home_ex2\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 269 features and 161 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 106.3831 ymin: -6.370815 xmax: 106.9728 ymax: -5.184322\nGeodetic CRS:  WGS 84\n\n\nWe will then perform a left join on this both of the data frame in order to find out which rows has empty data. We will make use of DESA and KELURAHAN as the common identifier.\n\njakarta_07_2021 <- left_join(Jakarta_Area, July_2021,\n                          by = c(\"DESA\" = \"KELURAHAN\"))\n\nOnce we join the data we have notice that that are 4 different rows with NA columns, 2 of them are expected, but the other 2 are a surprised:\n\nDANAU SUNTER\nDANAU SUNTER DLL\nJATIPULO\nKRENDANG\n\nI went to take a look at the data for the vaccination table and compare the results, and found that there is a slight difference in the name. The Jakarta sf Data frame record JATI PULO as JATIPULO, while for KERENDANG, it was recorded as KRENDANG instead.\nThere are 2 options to solve this issue. I can replace the name of the those two, but I choose to use the KODE_DESA and KODE KELURAHAN instead.\n\njakarta_07_2021 <- left_join(Jakarta_Area, July_2021,\n                             by = c(\"KODE_DESA\" = \"KODE KELURAHAN\"))\n\nWhen we look at the data, we spotted 2 different rows with NA.\n\nDANAU SUNTER\nDANAU SUNTER DLL\n\nWe can confirm that we can drop the columns already. We can perform the step with the code chunk below.\n\njakarta_07_2021 <- jakarta_07_2021 %>% drop_na()\n\nJust to give us a piece of mind, lets plot out the border\n\ntm_shape(jakarta_07_2021)+\n  tm_borders(alpha = 0.5) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)\n\n\n\n\nLooking at the map, notice how the map includes all the outer islands. This is not what this exercise is about as such we would need to remove all those data points.\nI have identified that all the outer islands belong district KEPULAUAN SERIBU. All we need to do is to filter out the data.\n\njakarta_07_2021_removed <- jakarta_07_2021 %>% \n  drop_na() %>%\n  filter(KAB_KOTA != \"KEPULAUAN SERIBU\")\n\nWe can plot again to make sure that we are correct.\n\ntm_shape(jakarta_07_2021_removed)+\n  tm_borders(alpha = 0.5) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)"
  },
  {
    "objectID": "lessons/Take-home/Take-home_ex2/Take-home_ex2.html#calculating-the-vaccination-rate",
    "href": "lessons/Take-home/Take-home_ex2/Take-home_ex2.html#calculating-the-vaccination-rate",
    "title": "Take Home Exercise 2",
    "section": "Calculating the Vaccination Rate",
    "text": "Calculating the Vaccination Rate\n\n\n\n\n\n\nDanger\n\n\n\nNote that in this case we are using the Target as the vaccination rate as it is a better representative values of the vaccination rate. This is because COVID 19 vaccine is given in 2 doses, it is possible that that the targeted will be greater than the population of Jakarta.\n\n\nNow that we have cleaned up the data we would need to map out the Monthly Vaccination Rate.\nTo Calculate Vaccination Rate, we would need to make some calculation as the vaccination data frame does not provide the vaccination rate directly, what was given however, is the amount of people not vaccination and the target vaccination. In this case we can use the formula:\nVaccination Rate = (Target - Not Vaccinated) / Target\nWe will be performing this calculation on the vaccination data frame. The code chunk below shows calculation of the vaccination rate into a new column\n\nvaccinated_july <- July_2021 %>% \n  mutate(vaccinated_rate = (`SASARAN` - `BELUM VAKSIN`)/`SASARAN`)\n\nNow we can take a look at the data.\n\nvaccinated_july\n\n# A tibble: 267 × 7\n   `KODE KELURAHAN` `WILAYAH KOTA`  KECAMATAN    KELUR…¹ SASARAN BELUM…² vacci…³\n   <chr>            <chr>           <chr>        <chr>     <dbl>   <dbl>   <dbl>\n 1 3172051003       JAKARTA UTARA   PADEMANGAN   ANCOL     20393   13272   0.349\n 2 3173041007       JAKARTA BARAT   TAMBORA      ANGKE     25785   16477   0.361\n 3 3175041005       JAKARTA TIMUR   KRAMAT JATI  BALE K…   25158   18849   0.251\n 4 3175031003       JAKARTA TIMUR   JATINEGARA   BALI M…    8683    5743   0.339\n 5 3175101006       JAKARTA TIMUR   CIPAYUNG     BAMBU …   22768   15407   0.323\n 6 3174031002       JAKARTA SELATAN MAMPANG PRA… BANGKA    18930   12503   0.340\n 7 3175051002       JAKARTA TIMUR   PASAR REBO   BARU      20267   11268   0.444\n 8 3175041004       JAKARTA TIMUR   KRAMAT JATI  BATU A…   41389   30358   0.267\n 9 3171071002       JAKARTA PUSAT   TANAH ABANG  BENDUN…   19008   11502   0.395\n10 3175031002       JAKARTA TIMUR   JATINEGARA   BIDARA…   32331   23395   0.276\n# … with 257 more rows, and abbreviated variable names ¹​KELURAHAN,\n#   ²​`BELUM VAKSIN`, ³​vaccinated_rate\n\n\nNotice that we have created a new column with the Vaccination Rate of the Month. With all that done we can perform our Task."
  },
  {
    "objectID": "lessons/Take-home/Take-home_ex2/Take-home_ex2.html#importing-aspatial-data",
    "href": "lessons/Take-home/Take-home_ex2/Take-home_ex2.html#importing-aspatial-data",
    "title": "Take Home Exercise 2",
    "section": "Importing Aspatial Data",
    "text": "Importing Aspatial Data\nThere is 12 datasets to be imported and we will be importing all of them in the code chunk below. At the same time we will also be filtering out the first row and selecting the relevant columns.\n\n\n\n\n\n\nNote\n\n\n\nFor the March Data, the data from the website reference 2 March instead.\n\n\n\njuly_2021 <- read_excel(\"data/aspatial/Data Vaksinasi Berbasis Kelurahan (01 Juli 2021).xlsx\") %>% \n  select(0:6) %>%\n  filter(!row_number() %in% c(1))\n\naug_2021 <- read_excel(\"data/aspatial/Data Vaksinasi Berbasis Kelurahan (1 Agustus 2021).xlsx\") %>% \n  select(0:6) %>%\n  filter(!row_number() %in% c(1))\n\nsept_2021 <- read_excel(\"data/aspatial/Data Vaksinasi Berbasis Kelurahan (01 September 2021).xlsx\") %>% \n  select(0:6) %>%\n  filter(!row_number() %in% c(1))\n\noct_2021 <- read_excel(\"data/aspatial/Data Vaksinasi Berbasis Kelurahan (01 Oktober 2021).xlsx\") %>% \n  select(0:6) %>%\n  filter(!row_number() %in% c(1))\n\nnov_2021 <- read_excel(\"data/aspatial/Data Vaksinasi Berbasis Kelurahan (01 November 2021).xlsx\") %>% \n  select(0:6) %>%\n  filter(!row_number() %in% c(1))\n\ndec_2021 <- read_excel(\"data/aspatial/Data Vaksinasi Berbasis Kelurahan (01 Desember 2021).xlsx\") %>% \n  select(0:6) %>%\n  filter(!row_number() %in% c(1))\n\njan_2022 <- read_excel(\"data/aspatial/Data Vaksinasi Berbasis Kelurahan (01 Januari 2022).xlsx\") %>% \n  select(0:6) %>%\n  filter(!row_number() %in% c(1))\n\nfeb_2022 <- read_excel(\"data/aspatial/Data Vaksinasi Berbasis Kelurahan (01 Februari 2022).xlsx\") %>% \n  select(0:6) %>%\n  filter(!row_number() %in% c(1))\n\nmar_2022 <- read_excel(\"data/aspatial/Data Vaksinasi Berbasis Kelurahan (02 Maret 2022).xlsx\") %>% \n  select(0:6) %>%\n  filter(!row_number() %in% c(1))\n\napr_2022 <- read_excel(\"data/aspatial/Data Vaksinasi Berbasis Kelurahan (01 April 2022).xlsx\") %>% \n  select(0:6) %>%\n  filter(!row_number() %in% c(1))\n\nmay_2022 <- read_excel(\"data/aspatial/Data Vaksinasi Berbasis Kelurahan (01 Mei 2022).xlsx\") %>% \n  select(0:6) %>%\n  filter(!row_number() %in% c(1))\n\njun_2022 <- read_excel(\"data/aspatial/Data Vaksinasi Berbasis Kelurahan (01 Juni 2022).xlsx\") %>% \n  select(0:6) %>%\n  filter(!row_number() %in% c(1))"
  },
  {
    "objectID": "lessons/Take-home/Take-home_ex2/Take-home_ex2.html#calculating-vaccination-rate",
    "href": "lessons/Take-home/Take-home_ex2/Take-home_ex2.html#calculating-vaccination-rate",
    "title": "Take Home Exercise 2",
    "section": "Calculating Vaccination Rate",
    "text": "Calculating Vaccination Rate\nNow we will be calculating the Monthly vaccination rate for each of the months. We will append the calculated rate to the end of the data frame.\n\nvaccinated_july <- july_2021 %>% \n  mutate(vaccinated_rate = (`SASARAN` - `BELUM VAKSIN`)/`SASARAN`)\n\nvaccinated_aug <- aug_2021 %>% \n  mutate(vaccinated_rate = (`SASARAN` - `BELUM VAKSIN`)/`SASARAN`)\n\nvaccinated_sept <- sept_2021 %>% \n  mutate(vaccinated_rate = (`SASARAN` - `BELUM VAKSIN`)/`SASARAN`)\n\nvaccinated_oct <- oct_2021 %>% \n  mutate(vaccinated_rate = (`SASARAN` - `BELUM VAKSIN`)/`SASARAN`)\n\nvaccinated_nov <- nov_2021 %>% \n  mutate(vaccinated_rate = (`SASARAN` - `BELUM VAKSIN`)/`SASARAN`)\n\nvaccinated_dec <- dec_2021 %>% \n  mutate(vaccinated_rate = (`SASARAN` - `BELUM VAKSIN`)/`SASARAN`)\n\nvaccinated_jan <- jan_2022 %>% \n  mutate(vaccinated_rate = (`SASARAN` - `BELUM VAKSIN`)/`SASARAN`)\n\nvaccinated_feb <- feb_2022 %>% \n  mutate(vaccinated_rate = (`SASARAN` - `BELUM VAKSIN`)/`SASARAN`)\n\nvaccinated_mar <- mar_2022 %>% \n  mutate(vaccinated_rate = (`SASARAN` - `BELUM VAKSIN`)/`SASARAN`)\n\nvaccinated_apr <- apr_2022 %>% \n  mutate(vaccinated_rate = (`SASARAN` - `BELUM VAKSIN`)/`SASARAN`)\n\nvaccinated_may <- may_2022 %>% \n  mutate(vaccinated_rate = (`SASARAN` - `BELUM VAKSIN`)/`SASARAN`)\n\nvaccinated_jun <- jun_2022 %>% \n  mutate(vaccinated_rate = (`SASARAN` - `BELUM VAKSIN`)/`SASARAN`)"
  },
  {
    "objectID": "lessons/Take-home/Take-home_ex2/Take-home_ex2.html#importing-geospatial-data",
    "href": "lessons/Take-home/Take-home_ex2/Take-home_ex2.html#importing-geospatial-data",
    "title": "Take Home Exercise 2",
    "section": "Importing Geospatial Data",
    "text": "Importing Geospatial Data\nNow that we have finish calculating the vaccination rate, we can now import the sf data frame.\nIn the code chunk below, we will be filtering the relevant columns. We will also be removing the 2 outer islands with NA in the rows. We also will be applying st_transform() to transform the data into the correct coordinate system.\n\njakarta_sf <- st_read(dsn = \"data/geospatial\", \n                 layer = \"BATAS_DESA_DESEMBER_2019_DUKCAPIL_DKI_JAKARTA\") %>%\n  select(0:9) %>%\n  drop_na() %>% \n  filter(KAB_KOTA != \"KEPULAUAN SERIBU\") %>%\n  st_transform(crs = 23845)\n\nReading layer `BATAS_DESA_DESEMBER_2019_DUKCAPIL_DKI_JAKARTA' from data source \n  `C:\\hxchen-2019\\birdie\\lessons\\Take-home\\Take-home_ex2\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 269 features and 161 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 106.3831 ymin: -6.370815 xmax: 106.9728 ymax: -5.184322\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "lessons/Take-home/Take-home_ex2/Take-home_ex2.html#merging-the-sf-data-frame",
    "href": "lessons/Take-home/Take-home_ex2/Take-home_ex2.html#merging-the-sf-data-frame",
    "title": "Take Home Exercise 2",
    "section": "Merging the SF data frame",
    "text": "Merging the SF data frame\nNow that we can do that we can now perform the merging of the sf data frame with the vaccination data frame. We will be joining by KODE_DESA and KODE KELURAHAN for simplicity.\n\njakarta_july <- left_join(jakarta_sf, vaccinated_july,\n                             by = c(\"KODE_DESA\" = \"KODE KELURAHAN\"))\n\njakarta_aug <- left_join(jakarta_sf, vaccinated_aug,\n                             by = c(\"KODE_DESA\" = \"KODE KELURAHAN\"))\n\njakarta_sept <- left_join(jakarta_sf, vaccinated_sept,\n                             by = c(\"KODE_DESA\" = \"KODE KELURAHAN\"))\n\njakarta_oct <- left_join(jakarta_sf, vaccinated_oct,\n                             by = c(\"KODE_DESA\" = \"KODE KELURAHAN\"))\n\njakarta_nov <- left_join(jakarta_sf, vaccinated_nov,\n                             by = c(\"KODE_DESA\" = \"KODE KELURAHAN\"))\n\njakarta_dec <- left_join(jakarta_sf, vaccinated_dec,\n                             by = c(\"KODE_DESA\" = \"KODE KELURAHAN\"))\n\njakarta_jan <- left_join(jakarta_sf, vaccinated_jan,\n                             by = c(\"KODE_DESA\" = \"KODE KELURAHAN\"))\n\njakarta_feb <- left_join(jakarta_sf, vaccinated_feb,\n                             by = c(\"KODE_DESA\" = \"KODE KELURAHAN\"))\n\njakarta_mar <- left_join(jakarta_sf, vaccinated_mar,\n                             by = c(\"KODE_DESA\" = \"KODE KELURAHAN\"))\n\njakarta_apr <- left_join(jakarta_sf, vaccinated_apr,\n                             by = c(\"KODE_DESA\" = \"KODE KELURAHAN\"))\n\njakarta_may <- left_join(jakarta_sf, vaccinated_may,\n                             by = c(\"KODE_DESA\" = \"KODE KELURAHAN\"))\n\njakarta_jun <- left_join(jakarta_sf, vaccinated_jun,\n                             by = c(\"KODE_DESA\" = \"KODE KELURAHAN\"))"
  },
  {
    "objectID": "lessons/Take-home/Take-home_ex2/Take-home_ex2.html#choropleth-maps-july-2021-to-june-2022",
    "href": "lessons/Take-home/Take-home_ex2/Take-home_ex2.html#choropleth-maps-july-2021-to-june-2022",
    "title": "Take Home Exercise 2",
    "section": "Choropleth Maps July 2021 to June 2022",
    "text": "Choropleth Maps July 2021 to June 2022\n\n\n\n\n\n\nNote\n\n\n\nWe will be setting the style of classification into “quantile” and setting the bins to 5.\n\n\nJuly 2021\n\njuly_choro <- tm_shape(jakarta_july)+\n  tm_fill(\"vaccinated_rate\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          n = 5,\n          title = \"Vaccination Rate\") +\n  tm_layout(main.title = \"Jakarta Vaccination Rate July 2021\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) \n\njuly_choro\n\n\n\n\nAugust 2021\n\naug_choro <- tm_shape(jakarta_aug)+\n  tm_fill(\"vaccinated_rate\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          n = 5,\n          title = \"Vaccination Rate\") +\n  tm_layout(main.title = \"Jakarta Vaccination Rate Aug 2021\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) \n\naug_choro\n\n\n\n\nSeptember 2021\n\nsept_choro <- tm_shape(jakarta_sept)+\n  tm_fill(\"vaccinated_rate\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          n = 5,\n          title = \"Vaccination Rate\") +\n  tm_layout(main.title = \"Jakarta Vaccination Rate Sept 2021\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5)\n\nsept_choro\n\n\n\n\nOctober 2021\n\noct_choro <- tm_shape(jakarta_oct)+\n  tm_fill(\"vaccinated_rate\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          n = 5,\n          title = \"Vaccination Rate\") +\n  tm_layout(main.title = \"Jakarta Vaccination Rate Oct 2021\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5)\n\noct_choro\n\n\n\n\nNovember 2021\n\nnov_choro <- tm_shape(jakarta_nov)+\n  tm_fill(\"vaccinated_rate\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          n = 5,\n          title = \"Vaccination Rate\") +\n  tm_layout(main.title = \"Jakarta Vaccination Rate Nov 2021\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) \n\nnov_choro\n\n\n\n\nDecember 2021\n\ndec_choro <- tm_shape(jakarta_dec)+\n  tm_fill(\"vaccinated_rate\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          n = 5,\n          title = \"Vaccination Rate\") +\n  tm_layout(main.title = \"Jakarta Vaccination Rate Dec 2021\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) \n\ndec_choro\n\n\n\n\nJanuary 2022\n\njan_choro <- tm_shape(jakarta_jan)+\n  tm_fill(\"vaccinated_rate\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          n = 5,\n          title = \"Vaccination Rate\") +\n  tm_layout(main.title = \"Jakarta Vaccination Rate Jan 2022\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) \n\njan_choro\n\n\n\n\nFebruary 2022\n\nfeb_choro <- tm_shape(jakarta_feb)+\n  tm_fill(\"vaccinated_rate\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          n = 5,\n          title = \"Vaccination Rate\") +\n  tm_layout(main.title = \"Jakarta Vaccination Rate Feb 2022\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_grid(alpha =0.2)\n\nfeb_choro\n\n\n\n\nMarch 2022\n\nmar_choro <- tm_shape(jakarta_mar)+\n  tm_fill(\"vaccinated_rate\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          n = 5,\n          title = \"Vaccination Rate\") +\n  tm_layout(main.title = \"Jakarta Vaccination Rate Mar 2022\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5)\n\nmar_choro\n\n\n\n\nApril 2022\n\napr_choro <- tm_shape(jakarta_apr)+\n  tm_fill(\"vaccinated_rate\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          n = 5,\n          title = \"Vaccination Rate\") +\n  tm_layout(main.title = \"Jakarta Vaccination Rate Apr 2022\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5)\n\napr_choro\n\n\n\n\nMay 2022\n\nmay_choro <- tm_shape(jakarta_may)+\n  tm_fill(\"vaccinated_rate\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          n = 5,\n          title = \"Vaccination Rate\") +\n  tm_layout(main.title = \"Jakarta Vaccination Rate May 2022\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) \n\nmay_choro\n\n\n\n\nJune 2022\n\njune_choro <- tm_shape(jakarta_jun)+\n  tm_fill(\"vaccinated_rate\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          n = 5,\n          title = \"Vaccination Rate\") +\n  tm_layout(main.title = \"Jakarta Vaccination Rate Jun 2022\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5)\n\njune_choro"
  },
  {
    "objectID": "lessons/Take-home/Take-home_ex2/Take-home_ex2.html#analysis-of-choropleth-map",
    "href": "lessons/Take-home/Take-home_ex2/Take-home_ex2.html#analysis-of-choropleth-map",
    "title": "Take Home Exercise 2",
    "section": "Analysis of Choropleth Map",
    "text": "Analysis of Choropleth Map\nTo make things easier for us to analyse, we will be arranging the maps into a grid of maps for us to see the pattern better.\n\ntmap_arrange(july_choro, aug_choro, asp = 1, ncol=2)\n\n\n\ntmap_arrange(sept_choro, oct_choro, asp = 1, ncol=2)\n\n\n\ntmap_arrange(nov_choro, dec_choro, asp = 1, ncol=2)\n\n\n\ntmap_arrange(jan_choro, feb_choro, asp = 1, ncol=2)\n\n\n\ntmap_arrange(mar_choro, apr_choro, asp = 1, ncol=2)\n\n\n\ntmap_arrange(may_choro, june_choro, asp = 1, ncol=2)\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nBased on the choropleths map plotted for the region of Jakarta, one pattern that was reviewed was that throughout the study period, the monthly vaccination rate of the entire region increases. The Monthly vaccination rate increases sharply up till the month of December before it slowed down significantly. Overall the vaccination rate throughout the region of Jakarta increases with the minimum rate increasing from 0.227 to 0781.\nHowever, one thing to note is the rate of change of vaccination rate differs significantly for each sub district. A district can fluctuate between upper quantile and the lower quantile throughout the period. This can be seen from the 2 district in the north-western region having the highest vaccination rates, but progress to a lower quantile throughout the month. The districts located at the south of Jakarta and a few districts near the north-east remains largely stable at the highest quantile throughout the period."
  },
  {
    "objectID": "lessons/Take-home/Take-home_ex2/Take-home_ex2.html#step-1-deriving-contiguity-weights.",
    "href": "lessons/Take-home/Take-home_ex2/Take-home_ex2.html#step-1-deriving-contiguity-weights.",
    "title": "Take Home Exercise 2",
    "section": "Step 1: Deriving contiguity weights.",
    "text": "Step 1: Deriving contiguity weights.\nBefore we calculate the Local Gi* Analysis, we would need to calculate the contiguity weights. This can be done with the code chunk below. The code chunk add 2 new columns, one of which is the idenitify nearest neighbors and the contain the weights matrix.\nWe will make use of the following functions from sfdep package:\n\nst_contiguity(): Identify the nearest neighbors. Find out more here.\nst_inverse_distance(): Calculate the inverse distance weighs. Find out more about here.\n\nThe code chunk below will compute the weight matrix for all the months:\n\nwm_jul <- jakarta_july %>%\n  mutate(nb = st_contiguity(geometry),\n         wts = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\n\n! Polygon provided. Using point on surface.\n\nwm_aug <- jakarta_aug %>%\n  mutate(nb = st_contiguity(geometry),\n         wts = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\n\n! Polygon provided. Using point on surface.\n\nwm_sept <- jakarta_sept %>%\n  mutate(nb = st_contiguity(geometry),\n         wts = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\n\n! Polygon provided. Using point on surface.\n\nwm_oct <- jakarta_oct %>%\n  mutate(nb = st_contiguity(geometry),\n         wts = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\n\n! Polygon provided. Using point on surface.\n\nwm_nov <- jakarta_nov %>%\n  mutate(nb = st_contiguity(geometry),\n         wts = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\n\n! Polygon provided. Using point on surface.\n\nwm_dec <- jakarta_dec %>%\n  mutate(nb = st_contiguity(geometry),\n         wts = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\n\n! Polygon provided. Using point on surface.\n\nwm_jan <- jakarta_jan %>%\n  mutate(nb = st_contiguity(geometry),\n         wts = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\n\n! Polygon provided. Using point on surface.\n\nwm_feb <- jakarta_feb %>%\n  mutate(nb = st_contiguity(geometry),\n         wts = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\n\n! Polygon provided. Using point on surface.\n\nwm_mar <- jakarta_mar %>%\n  mutate(nb = st_contiguity(geometry),\n         wts = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\n\n! Polygon provided. Using point on surface.\n\nwm_apr <- jakarta_apr %>%\n  mutate(nb = st_contiguity(geometry),\n         wts = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\n\n! Polygon provided. Using point on surface.\n\nwm_may <- jakarta_may %>%\n  mutate(nb = st_contiguity(geometry),\n         wts = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\n\n! Polygon provided. Using point on surface.\n\nwm_jun <- jakarta_jun %>%\n  mutate(nb = st_contiguity(geometry),\n         wts = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\n\n! Polygon provided. Using point on surface."
  },
  {
    "objectID": "lessons/Take-home/Take-home_ex2/Take-home_ex2.html#step-2-calculating-gi-statistic",
    "href": "lessons/Take-home/Take-home_ex2/Take-home_ex2.html#step-2-calculating-gi-statistic",
    "title": "Take Home Exercise 2",
    "section": "Step 2: Calculating Gi* Statistic",
    "text": "Step 2: Calculating Gi* Statistic\nNow that we have the computed the weights of each for each of the vaccination rate, we can calculate the local Gi* as well. In this step, we will be performing a monte carlo simulation on the values as well.\nWe will be making use of the following function from the sfdep package:\n\nlocal_gstar_perm(): Calculate the Gi* values with simulation. It takes the target variable, nearest neighbor and weight matrix and the number of simulation. Find out more here.\n\nThe code chunk below will compute the weight matrix for all the months:\n\nHCSA_jul <- wm_jul %>% \n  mutate(local_Gi = local_gstar_perm(\n    vaccinated_rate, nb, wt, nsim = 99),\n         .before = 1) %>%\n  unnest(local_Gi)\n\nHCSA_aug <- wm_aug %>% \n  mutate(local_Gi = local_gstar_perm(\n    vaccinated_rate, nb, wt, nsim = 99),\n         .before = 1) %>%\n  unnest(local_Gi)\n\nHCSA_sept <- wm_sept %>% \n  mutate(local_Gi = local_gstar_perm(\n    vaccinated_rate, nb, wt, nsim = 99),\n         .before = 1) %>%\n  unnest(local_Gi)\n\nHCSA_oct <- wm_oct %>% \n  mutate(local_Gi = local_gstar_perm(\n    vaccinated_rate, nb, wt, nsim = 99),\n         .before = 1) %>%\n  unnest(local_Gi)\n\nHCSA_nov <- wm_nov %>% \n  mutate(local_Gi = local_gstar_perm(\n    vaccinated_rate, nb, wt, nsim = 99),\n         .before = 1) %>%\n  unnest(local_Gi)\n\nHCSA_dec <- wm_dec %>% \n  mutate(local_Gi = local_gstar_perm(\n    vaccinated_rate, nb, wt, nsim = 99),\n         .before = 1) %>%\n  unnest(local_Gi)\n\nHCSA_jan <- wm_jan %>% \n  mutate(local_Gi = local_gstar_perm(\n    vaccinated_rate, nb, wt, nsim = 99),\n         .before = 1) %>%\n  unnest(local_Gi)\n\nHCSA_feb <- wm_feb %>% \n  mutate(local_Gi = local_gstar_perm(\n    vaccinated_rate, nb, wt, nsim = 99),\n         .before = 1) %>%\n  unnest(local_Gi)\n\nHCSA_mar <- wm_mar %>% \n  mutate(local_Gi = local_gstar_perm(\n    vaccinated_rate, nb, wt, nsim = 99),\n         .before = 1) %>%\n  unnest(local_Gi)\n\nHCSA_apr <- wm_apr %>% \n  mutate(local_Gi = local_gstar_perm(\n    vaccinated_rate, nb, wt, nsim = 99),\n         .before = 1) %>%\n  unnest(local_Gi)\n\nHCSA_may <- wm_may %>% \n  mutate(local_Gi = local_gstar_perm(\n    vaccinated_rate, nb, wt, nsim = 99),\n         .before = 1) %>%\n  unnest(local_Gi)\n\nHCSA_jun <- wm_jun %>% \n  mutate(local_Gi = local_gstar_perm(\n    vaccinated_rate, nb, wt, nsim = 99),\n         .before = 1) %>%\n  unnest(local_Gi)"
  },
  {
    "objectID": "lessons/Take-home/Take-home_ex2/Take-home_ex2.html#step-3-visualization-gi",
    "href": "lessons/Take-home/Take-home_ex2/Take-home_ex2.html#step-3-visualization-gi",
    "title": "Take Home Exercise 2",
    "section": "Step 3: Visualization Gi*",
    "text": "Step 3: Visualization Gi*\nNow that we have calculated the Gi* values we can visualize it\n\nLooking at the Visualisation\n\nmap1 <- tm_shape(HCSA_jul)+\n  tm_fill(\"gi_star\")+  \n  tm_layout(main.title = \"Gi* of July 2021\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) \n\nmap1\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\nJust looking at the map above does not seems to indicate, but that is not enough for us to make a conclusion. We would need to compare it with the p-value. Lets compare it with the p-value map\n\np_map <- tm_shape(HCSA_jul)+\n    tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_layout(main.title = \"p-value of Gi*\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) \n\ntmap_arrange(map1, p_map, ncol = 2)\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\nWarning: Values have found that are less than the lowest break\n\n\nWarning: Values have found that are higher than the highest break\n\n\nVariable(s) \"p_value\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\nWe will need to plot out the areas that are of significant p-value. In this case we are selecting 95% significant level as selecting 99% will give an error.\n\nHCSA_jul_sig <- HCSA_jul  %>%\n  filter(p_sim < 0.05)\n\n\nHCSA_jul_map <- tm_shape(HCSA_jul)+\n  tm_polygons()+\n  tm_shape(HCSA_jul_sig)+\n  tm_fill(\"gi_star\")+  \n  tm_layout(main.title = \"HCSA July 2021\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5)\n\nHCSA_jul_map\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\nNow that we are able to better see the Cold Spot and Hot Spot, we can better come to a conclusion.\n\n\nFiltering of significant value\nThe code chunk below will filter out the value of significant value less than 0.05.\n\nHCSA_aug_sig <- HCSA_aug  %>%\n  filter(p_sim < 0.05)\n\nHCSA_sept_sig <- HCSA_sept  %>%\n  filter(p_sim < 0.05)\n\nHCSA_oct_sig <- HCSA_oct  %>%\n  filter(p_sim < 0.05)\n\nHCSA_nov_sig <- HCSA_nov  %>%\n  filter(p_sim < 0.05)\n\nHCSA_dec_sig <- HCSA_dec  %>%\n  filter(p_sim < 0.05)\n\nHCSA_jan_sig <- HCSA_jan  %>%\n  filter(p_sim < 0.05)\n\nHCSA_feb_sig <- HCSA_feb  %>%\n  filter(p_sim < 0.05)\n\nHCSA_mar_sig <- HCSA_mar  %>%\n  filter(p_sim < 0.05)\n\nHCSA_apr_sig <- HCSA_apr  %>%\n  filter(p_sim < 0.05)\n\nHCSA_may_sig <- HCSA_may  %>%\n  filter(p_sim < 0.05)\n\nHCSA_jun_sig <- HCSA_jun  %>%\n  filter(p_sim < 0.05)\n\n\n\nVisualizing Hot Spot and Cold Spot Area\n\n\n\n\n\n\nNote\n\n\n\nAll the maps here are images and not rendered as the map changes due to the use of monte carlo simulation. The map you generated might be different.\n\n\nJuly 2021\n\nHCSA_jul_map\n\n\n\n\n\n\n\n\nImportant\n\n\n\nBased on a 95% confidence interval, we can conclude that there is a total of 5 cold spot areas and 5 hot spot areas for July 2021.\n\n\nAugust 2021\n\nHCSA_aug_map <- tm_shape(HCSA_aug)+\n  tm_polygons()+\n  tm_shape(HCSA_aug_sig)+\n  tm_fill(\"gi_star\")+  \n  tm_layout(main.title = \"HCSA August 2021\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5)\n\nHCSA_aug_map\n\n\n\n\n\n\n\n\nImportant\n\n\n\nBased on a 95% confidence interval, we can conclude that there is a total of 4 cold spot areas and 3 hot spot areas for August 2021\n\n\nSeptember 2021\n\nHCSA_sept_map <- tm_shape(HCSA_sept)+\n  tm_polygons()+\n  tm_shape(HCSA_sept_sig)+\n  tm_fill(\"gi_star\")+  \n  tm_layout(main.title = \"HCSA September 2021\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5)\n\nHCSA_sept_map\n\n\n\n\n\n\n\n\nImportant\n\n\n\nBased on a 95% confidence interval, we can conclude that there is a total of 5 cold spot areas and 4 hot spot areas for September 2021\n\n\nOctober 2021\n\nHCSA_oct_map <- tm_shape(HCSA_oct)+\n  tm_polygons()+\n  tm_shape(HCSA_oct_sig)+\n  tm_fill(\"gi_star\")+  \n  tm_layout(main.title = \"HCSA October 2021\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5)\n\nHCSA_oct_map\n\n\n\n\n\n\n\n\nImportant\n\n\n\nBased on a 95% confidence interval, we can conclude that there is a total of 6 cold spot areas and 6 hot spot areas for October 2021\n\n\nNovember 2021\n\nHCSA_nov_map <- tm_shape(HCSA_nov)+\n  tm_polygons()+\n  tm_shape(HCSA_nov_sig)+\n  tm_fill(\"gi_star\")+  \n  tm_layout(main.title = \"HCSA November 2021\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5)\n\nHCSA_nov_map\n\n\n\n\n\n\n\n\nImportant\n\n\n\nBased on a 95% confidence interval, we can conclude that there is a total of 5 cold spot areas and 5 hot spot areas for November 2021.\n\n\nDecember 2021\n\nHCSA_dec_map <- tm_shape(HCSA_dec)+\n  tm_polygons()+\n  tm_shape(HCSA_dec_sig)+\n  tm_fill(\"gi_star\")+  \n  tm_layout(main.title = \"HCSA December 2021\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5)\n\nHCSA_dec_map\n\n\n\n\n\n\n\n\nImportant\n\n\n\nBased on a 95% confidence interval, we can conclude that there is a total of 4 cold spot areas and 3 hot spot areas for December 2021\n\n\nJanuary 2022\n\nHCSA_jan_map <- tm_shape(HCSA_jan)+\n  tm_polygons()+\n  tm_shape(HCSA_jan_sig)+\n  tm_fill(\"gi_star\")+  \n  tm_layout(main.title = \"HCSA January 2022\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5)\n\nHCSA_jan_map\n\n\n\n\n\n\n\n\nImportant\n\n\n\nBased on a 95% confidence interval, we can conclude that there is a total of 4 cold spot areas and 4 hot spot areas for January 2022\n\n\nFebruary 2022\n\nHCSA_feb_map <- tm_shape(HCSA_feb)+\n  tm_polygons()+\n  tm_shape(HCSA_feb_sig)+\n  tm_fill(\"gi_star\")+  \n  tm_layout(main.title = \"HCSA February 2022\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5)\n\nHCSA_feb_map\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nBased on a 95% confidence interval, we can conclude that there is a total of 4 cold spot areas and 6 hot spot areas for February 2022.\n\n\nMarch 2022\n\nHCSA_mar_map <- tm_shape(HCSA_mar)+\n  tm_polygons()+\n  tm_shape(HCSA_mar_sig)+\n  tm_fill(\"gi_star\")+  \n  tm_layout(main.title = \"HCSA March 2022\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5)\n\nHCSA_mar_map\n\n\n\n\n\n\n\n\nImportant\n\n\n\nBased on a 95% confidence interval, we can conclude that there is a total of 4 cold spot areas and 4 hot spot areas for March 2022\n\n\nApril 2022\n\nHCSA_apr_map <- tm_shape(HCSA_apr)+\n  tm_polygons()+\n  tm_shape(HCSA_apr_sig)+\n  tm_fill(\"gi_star\")+  \n  tm_layout(main.title = \"HCSA April 2022\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5)\n\nHCSA_apr_map\n\n\n\n\n\n\n\n\nImportant\n\n\n\nBased on a 95% confidence interval, we can conclude that there is a total of 4 cold spot areas and 6 hot spot areas for April 2022.\n\n\nMay 2022\n\nHCSA_may_map <- tm_shape(HCSA_may)+\n  tm_polygons()+\n  tm_shape(HCSA_may_sig)+\n  tm_fill(\"gi_star\")+  \n  tm_layout(main.title = \"HCSA May 2022\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5)\n\nHCSA_may_map\n\n\n\n\n\n\n\n\nImportant\n\n\n\nBased on a 95% confidence interval, we can conclude that there is a total of 4 cold spot areas and 5 hot spot areas for May 2022.\n\n\nJune 2022\n\nHCSA_jun_map <- tm_shape(HCSA_jun)+\n  tm_polygons()+\n  tm_shape(HCSA_jun_sig)+\n  tm_fill(\"gi_star\")+  \n  tm_layout(main.title = \"HCSA June 2022\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5)\n\nHCSA_jun_map\n\n\n\n\n\n\n\n\nImportant\n\n\n\nBased on a 95% confidence interval, we can conclude that there is a total of 4 cold spot areas and 6 hot spot areas for June 2022."
  },
  {
    "objectID": "lessons/Take-home/Take-home_ex2/Take-home_ex2.html#preparing-the-data-for-ehsa",
    "href": "lessons/Take-home/Take-home_ex2/Take-home_ex2.html#preparing-the-data-for-ehsa",
    "title": "Take Home Exercise 2",
    "section": "Preparing the Data for EHSA",
    "text": "Preparing the Data for EHSA\nAs our Vaccination Rate Data is found in a different files we would need to combine them together to form a data set that we can use.\n\ndf <- tibble(\"month\" = as.Date(\"01/07/2021\", \"%m/%d/%Y\"), \n             \"DESA\" = jakarta_july %>% pull(DESA),\n             \"vaccinated_rate\" = jakarta_july %>% pull(vaccinated_rate))\n\ndf <- df %>% add_row(\"month\" = as.Date(\"01/08/2021\", \"%m/%d/%Y\"), \n               \"DESA\" = jakarta_aug %>% pull(DESA),\n               \"vaccinated_rate\" = jakarta_aug %>% pull(vaccinated_rate))\n\ndf <- df %>% add_row(\"month\" = as.Date(\"01/09/2021\", \"%m/%d/%Y\"), \n               \"DESA\" = jakarta_sept %>% pull(DESA),\n               \"vaccinated_rate\" = jakarta_sept %>% pull(vaccinated_rate))\n\ndf <- df %>% add_row(\"month\" = as.Date(\"01/10/2021\", \"%m/%d/%Y\"), \n               \"DESA\" = jakarta_oct %>% pull(DESA),\n               \"vaccinated_rate\" = jakarta_oct %>% pull(vaccinated_rate))\n\ndf <- df %>% add_row(\"month\" = as.Date(\"01/11/2021\", \"%m/%d/%Y\"), \n               \"DESA\" = jakarta_nov %>% pull(DESA),\n               \"vaccinated_rate\" = jakarta_nov %>% pull(vaccinated_rate))\n\ndf <- df %>% add_row(\"month\" = as.Date(\"01/12/2021\", \"%m/%d/%Y\"), \n               \"DESA\" = jakarta_dec %>% pull(DESA),\n               \"vaccinated_rate\" = jakarta_dec %>% pull(vaccinated_rate))\n\ndf <- df %>% add_row(\"month\" = as.Date(\"01/01/2022\", \"%m/%d/%Y\"), \n               \"DESA\" = jakarta_jan %>% pull(DESA),\n               \"vaccinated_rate\" = jakarta_jan %>% pull(vaccinated_rate))\n\ndf <- df %>% add_row(\"month\" = as.Date(\"01/02/2022\", \"%m/%d/%Y\"), \n               \"DESA\" = jakarta_feb %>% pull(DESA),\n               \"vaccinated_rate\" = jakarta_feb %>% pull(vaccinated_rate))\n\ndf <- df %>% add_row(\"month\" = as.Date(\"02/03/2022\", \"%m/%d/%Y\"), \n               \"DESA\" = jakarta_mar %>% pull(DESA),\n               \"vaccinated_rate\" = jakarta_mar %>% pull(vaccinated_rate))\n\ndf <- df %>% add_row(\"month\" = as.Date(\"01/04/2022\", \"%m/%d/%Y\"), \n               \"DESA\" = jakarta_apr %>% pull(DESA),\n               \"vaccinated_rate\" = jakarta_apr %>% pull(vaccinated_rate))\n\ndf <- df %>% add_row(\"month\" = as.Date(\"01/05/2022\", \"%m/%d/%Y\"), \n               \"DESA\" = jakarta_may %>% pull(DESA),\n               \"vaccinated_rate\" = jakarta_may %>% pull(vaccinated_rate))\n\ndf <- df %>% add_row(\"month\" = as.Date(\"01/06/2022\", \"%m/%d/%Y\"), \n               \"DESA\" = jakarta_jun %>% pull(DESA),\n               \"vaccinated_rate\" = jakarta_jun %>% pull(vaccinated_rate))\n\nLets take a look at our new data frame with all the information.\n\ndf\n\n# A tibble: 3,132 × 3\n   month      DESA               vaccinated_rate\n   <date>     <chr>                        <dbl>\n 1 2021-01-07 KEAGUNGAN                    0.327\n 2 2021-01-07 GLODOK                       0.505\n 3 2021-01-07 HARAPAN MULIA                0.318\n 4 2021-01-07 CEMPAKA BARU                 0.326\n 5 2021-01-07 PASAR BARU                   0.479\n 6 2021-01-07 KARANG ANYAR                 0.348\n 7 2021-01-07 MANGGA DUA SELATAN           0.351\n 8 2021-01-07 PETOJO UTARA                 0.347\n 9 2021-01-07 SENEN                        0.396\n10 2021-01-07 BUNGUR                       0.374\n# … with 3,122 more rows\n\n\nAs we have not filter out the Outer Islands in the original sf data frame we can perform the task here:\n\nJakarta_Area_cleaned <- Jakarta_Area %>%\n  filter(KAB_KOTA != \"KEPULAUAN SERIBU\")"
  },
  {
    "objectID": "lessons/Take-home/Take-home_ex2/Take-home_ex2.html#performing-man-kendall-test",
    "href": "lessons/Take-home/Take-home_ex2/Take-home_ex2.html#performing-man-kendall-test",
    "title": "Take Home Exercise 2",
    "section": "Performing Man-Kendall Test",
    "text": "Performing Man-Kendall Test\n\nStep 1: Calculating Space Time Cube\nOnce we have both the time series data of the Vaccination Rate and the filtered sf data frame, we can create a space time cube using the spacetime() function. Find out more here.\n\nvaccinated_rate_st <- spacetime(df, Jakarta_Area_cleaned,\n                      .loc_col = \"DESA\",\n                      .time_col = \"month\")\n\nWe will then verified that the time series cube is correct.\n\nis_spacetime_cube(vaccinated_rate_st)\n\n[1] TRUE\n\n\n\n\nStep 2: Calculating the Spatial Weights\nIn the code chunk below, multiple actions are being done. Firstly, we will need to activate the geometry context of the space time cube, and we will create 2 new rows for the nearest neighbors and weight matrix (similar to what was done above). The difference is that because this exist as a space time cube, we will need to incorporate the weight matrix and nearest neighbors to each time slice. The following new functions are used:\n\nactivate(): activate the geometry context\nset_nbs() and set_wts(): create a new column in the data context with the same name as the column in the geometry context. Find out more here.\n\n\nvaccinated_rate_nb <- vaccinated_rate_st %>%\n  activate(\"geometry\") %>%\n  mutate(nb = include_self(st_contiguity(geometry)),\n         wt = st_inverse_distance(nb, geometry,\n                                  scale = 1,\n                                  alpha = 1),\n         .before = 1) %>%\n  set_nbs(\"nb\") %>%\n  set_wts(\"wt\")\n\n! Polygon provided. Using point on surface.\n\n\nWarning in st_point_on_surface.sfc(geometry): st_point_on_surface may not give\ncorrect results for longitude/latitude data\n\n\n\n\nStep 3: Computing Gi*\nThis code chunk below calculate calculate the local Gi* for each district and month. It is similar in code to that of computing Gi* individually.\n\ngi_stars <- vaccinated_rate_nb %>% \n  group_by(month) %>% \n  mutate(gi_star = local_gstar_perm(\n    vaccinated_rate, nb, wt)) %>% \n  tidyr::unnest(gi_star)\n\n\n\nStep 4: Performing Man-Kendall Test\nIn this step, we will be performing Man-Kendall Test on each of sub district. In this case we are using the MannKendall() from the Kendall package.\n\nMannKendall(): It is a test for monotonic trend in a time series z[t] based on the Kendall rank correlation of z[t] and t. Find out more here.\n\n\nehsa <- gi_stars %>%\n  group_by(DESA) %>%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %>%\n  tidyr::unnest_wider(mk)"
  },
  {
    "objectID": "lessons/Take-home/Take-home_ex2/Take-home_ex2.html#temporal-trends",
    "href": "lessons/Take-home/Take-home_ex2/Take-home_ex2.html#temporal-trends",
    "title": "Take Home Exercise 2",
    "section": "Temporal Trends",
    "text": "Temporal Trends\nIn this section, we will be performing a deep dive into 3 different sub district and we will be analyzing the temporal trends in the area. In this case 3 sub district were selected:\n\nGEDONG: A sub district of PASAR REBO, which became a hot spot from November 2011\nKOJA: A sub district of KOJA, which is consistently a cold spot\nGELORA: A sub district of TANAH ABANG, central Jakarta with a lot of fluctuation\n\nWe will be plotting the various Graphs of the Gi* value for each of the region.\nFor this Kendall-Mann Test, we are evaluating the following Hypothesis\n\nNull hypothesis: There is no monotonic trend in the series.\nAlternate hypothesis: A trend exists. This trend can be positive, negative, or non-null.\n\n\nTemporal Trends of GEDONG sub district\n\ngedong <- gi_stars %>% \n  ungroup() %>% \n  filter(DESA == \"GEDONG\") |> \n  select(DESA, month, gi_star)\n\n\ngedong_plot <- ggplot(data = gedong, \n       aes(x = month, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\nggplotly(gedong_plot)\n\n\n\n\n\n\ngedong %>%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %>% \n  tidyr::unnest_wider(mk)\n\n# A tibble: 1 × 5\n    tau      sl     S     D  varS\n  <dbl>   <dbl> <dbl> <dbl> <dbl>\n1 0.727 0.00127    48  66.0  213.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIn the above result, the sI is the p-value, while the S value represents the direction of the trend.\nAs the p-value < 0.05, we must reject the null Hypothesis. we can conclude that is a significant upward trend, based with a confidence of 95%. In other words, this is a sign of emerging hot spot.\n\n\n\n\nTemporal Trends of KOJA sub district\n\nkoja <- gi_stars %>% \n  ungroup() %>% \n  filter(DESA == \"KOJA\") |> \n  select(DESA, month, gi_star)\n\n\nkoja_plot <- ggplot(data = koja, \n       aes(x = month, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\nggplotly(koja_plot)\n\n\n\n\n\n\nkoja %>%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %>% \n  tidyr::unnest_wider(mk)\n\n# A tibble: 1 × 5\n     tau    sl     S     D  varS\n   <dbl> <dbl> <dbl> <dbl> <dbl>\n1 0.0303 0.945     2  66.0  213.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIn the above result, the sI is the p-value, while the S value represents the direction of the trend.\nAs the p-value > 0.05, we must not reject the null Hypothesis. We can conclude that is a upward but insignificant trend, based with a confidence of 95%.\n\n\n\n\nTemporal Trends of GELORA sub district\n\ngelora <- gi_stars %>% \n  ungroup() %>% \n  filter(DESA == \"GELORA\") |> \n  select(DESA, month, gi_star)\n\n\ngelora_plot <- ggplot(data = gelora, \n       aes(x = month, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\nggplotly(gelora_plot)\n\n\n\n\n\n\ngelora %>%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %>% \n  tidyr::unnest_wider(mk)\n\n# A tibble: 1 × 5\n     tau       sl     S     D  varS\n   <dbl>    <dbl> <dbl> <dbl> <dbl>\n1 -0.818 0.000279   -54  66.0  213.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIn the above result, the sI is the p-value, while the S value represents the direction of the trend.\nAs the p-value < 0.05, we must reject the null Hypothesis. We can conclude that is a significant downward trend, based with a confidence of 95%. In other words, this is an emerging cold spot."
  },
  {
    "objectID": "lessons/Take-home/Take-home_ex2/Take-home_ex2.html#plotting-an-ehsa-map",
    "href": "lessons/Take-home/Take-home_ex2/Take-home_ex2.html#plotting-an-ehsa-map",
    "title": "Take Home Exercise 2",
    "section": "Plotting an EHSA Map",
    "text": "Plotting an EHSA Map\nNow that we can infer the trend from some smaller district lets look at the entire Jakarta as a whole.\n\nViewing Classification Hot and Cold Spots\nWe can make use of the emerging_hotspot_analysis() function. It takes the space time cube and combines the Gi* statistic with the Mann-Kendall test to determine if there is a temporal trend associated with local clustering of hot and cold spots. Find out more here.\n\nehsa_analysis <- emerging_hotspot_analysis(\n  x = vaccinated_rate_st, \n  .var = \"vaccinated_rate\", \n  k = 1, \n  nsim = 99\n)\n\nAfter we have completed that, lets take a look at the data.\n\nehsa_analysis\n\n# A tibble: 261 × 4\n   location             tau  p_value classification    \n   <chr>              <dbl>    <dbl> <chr>             \n 1 KEAGUNGAN          0.576 0.0112   oscilating hotspot\n 2 GLODOK             0.606 0.00749  sporadic coldspot \n 3 HARAPAN MULIA      0.636 0.00493  sporadic coldspot \n 4 CEMPAKA BARU       0.636 0.00493  sporadic coldspot \n 5 PASAR BARU         0.848 0.000162 oscilating hotspot\n 6 KARANG ANYAR       0.576 0.0112   oscilating hotspot\n 7 MANGGA DUA SELATAN 0.848 0.000162 oscilating hotspot\n 8 PETOJO UTARA       0.606 0.00749  sporadic coldspot \n 9 SENEN              0.273 0.244    sporadic coldspot \n10 BUNGUR             0.636 0.00493  sporadic coldspot \n# … with 251 more rows\n\n\nNow, we can see a bar graph of the different classification.\n\nehsa_plot <- ggplot(data = ehsa_analysis,\n       aes(x = classification)) +\n  geom_bar()\n\nggplotly(ehsa_plot)\n\n\n\n\n\n\n\nPlotting EHSA Data\n\n\n\n\n\n\nNote\n\n\n\nOne Assumption I made in the plotting the EHSA data is that a Mann-Kendall Test is usually done to determine if the area is an Emerging Hot Spot or Cold Spot. Mann-Kendall Test uses the G* values to calculate the\n\n\nBefore we can plot the EHSA data, we once again need to combine the data with a sf data frame.\n\njakarta_ehsa <- left_join(Jakarta_Area_cleaned, ehsa_analysis,\n                          by = c(\"DESA\" = \"location\"))\n\nNow that we have the necessary data, we will need to filter out the classification that are not significant.\n\nehsa_sig <- jakarta_ehsa  %>%\n  filter(p_value < 0.05)\n\nWe can now plot the graph.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(jakarta_ehsa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(ehsa_sig) +\n  tm_fill(\"classification\") + \n  tm_borders(alpha = 0.4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nAt a 95% confidence level, based on the Heat Map above, we can determine that most of the areas in Jakarta are oscillating hot spot. This is followed by most areas being sporadic cold spot and then oscillating cold spot and finally no pattern being the detected.\nThe gray out area are areas that are insignificant.\nAn oscillating hot spot is expected to dominate most of the areas of the region as it make sense that most of the area have an history of being a cold spot most of the time, as government have not ramp up vaccination efforts there. An oscillating cold spot likewise is expected to dominate with opposite taking placing, with the government slowing down their efforts there. What is surprising is that there are sporadic cold spot takes second place, as this indicate, that the effort spend there is constantly shifting, most likely to the areas of oscillating hot spot as all sporadic cold spot borders at least one oscillating hot spot."
  }
]